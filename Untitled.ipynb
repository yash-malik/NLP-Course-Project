{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideas\n",
    "\n",
    "# 1. chose only words with specific gender (M or F) and try binary classification\n",
    "\n",
    "# 2. reject words with empty gender and try (i) ternary classication (ii) multi-label classification\n",
    "\n",
    "# 3. reject proper nouns and similar\n",
    "# analyze categorywise (NN, VM, VAUX, ...)\n",
    "\n",
    "# try processing the complete sentence for better performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107652\n",
      "10845\n"
     ]
    }
   ],
   "source": [
    "# processing the dataset\n",
    "import os\n",
    "\n",
    "DATADIR = \"/home/yash/Desktop/NLP-Project/dataset\"\n",
    "CHUNKS = [\"InterChunk\", \"IntraChunk\"]\n",
    "NOTATIONS = [\"utf\", \"wx\"]\n",
    "TRAIN_SRCS = [\"conversation\", \"news_articles_and_heritage/Training\"]\n",
    "DEV_SRCS = [\"news_articles_and_heritage/Development\"]\n",
    "TEST_SRCS = [\"news_articles_and_heritage/Testing\"]\n",
    "\n",
    "# word mapping to category and gender\n",
    "word_info = {}\n",
    "\n",
    "# handle exceptions\n",
    "exceptions = []\n",
    "removed_words = set()\n",
    "\n",
    "def prepare_sets(SRCS):\n",
    "    data = []\n",
    "    for source in SRCS:\n",
    "        path = os.path.join(DATADIR, CHUNKS[0], NOTATIONS[0], source)\n",
    "        for data_file in os.listdir(path):\n",
    "\n",
    "            # print(data_file)\n",
    "            try:\n",
    "                f = open(os.path.join(path, data_file), \"r\")\n",
    "            except:\n",
    "                print(\"Can not open :\" + os.path.join(path, data_file))\n",
    "                break\n",
    "\n",
    "            for line in f:\n",
    "\n",
    "                cols = line.split(\"\\t\")\n",
    "                if len(cols) < 6:\n",
    "                    continue\n",
    "\n",
    "                attributes = cols[5].split(\"|\")\n",
    "                gender = attributes[1].split(\"-\")[1]\n",
    "                word = cols[1]\n",
    "                category = cols[4]\n",
    "\n",
    "                # multiple gender or no gender\n",
    "                if word in removed_words:\n",
    "                    continue\n",
    "\n",
    "                # if gender is not specified\n",
    "                if not gender:\n",
    "                    # exceptions.append([word, [category, gender]])\n",
    "                    removed_words.add(gender)\n",
    "                    continue\n",
    "\n",
    "                if word in word_info:\n",
    "                    # different [gender]\n",
    "                    if word_info[word][1] != gender:\n",
    "                        exceptions.append([word, word_info[word]])\n",
    "                        exceptions.append([word, [category, gender]])\n",
    "                        word_info.pop(word)\n",
    "                        removed_words.add(word)\n",
    "                        continue\n",
    "\n",
    "                word_info[word] = [category, gender]\n",
    "\n",
    "                if gender not in [\"m\", \"f\", \"any\"]:\n",
    "                    continue\n",
    "\n",
    "                chars = \"\"\n",
    "                for c in word:\n",
    "                    chars += c\n",
    "                    chars += \" \"\n",
    "                chars = chars[:-1]\n",
    "\n",
    "                # add to the data\n",
    "                data.append([chars, gender])\n",
    "                \n",
    "    return data\n",
    "\n",
    "\n",
    "training_data = prepare_sets(TRAIN_SRCS)\n",
    "test_data = prepare_sets(DEV_SRCS)\n",
    "print(len(training_data))\n",
    "print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['र ख े', 'ख ं भ े', 'व ् य व स ् थ ा', 'ज ि स क ी', 'म ह ि ल ा', 'ज ा र ी', 'ग ि र ो ह', 'उ त ् प ा द न', 'ब द ल ा व', 'प ह ु ं च ा']\n",
      "[[0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(training_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "\n",
    "def prepare_Xy_binary(data, X, y):\n",
    "    for features, label in data:\n",
    "        if label == \"any\":\n",
    "            continue\n",
    "        X.append(features)\n",
    "        if label == \"f\":\n",
    "            y.append(0)\n",
    "        elif label == \"m\":\n",
    "            y.append(1)\n",
    "\n",
    "\n",
    "def prepare_Xy_ternary(data, X, y):\n",
    "    for features, label in data:\n",
    "        X.append(features)\n",
    "        y.append([0, 0, 0])\n",
    "        if label == \"f\":\n",
    "            y[-1][0] = 1\n",
    "        elif label == \"m\":\n",
    "            y[-1][1] = 1\n",
    "        else:\n",
    "            y[-1][2] = 1\n",
    "\n",
    "\n",
    "def prepare_Xy_binary_multi_label(data, X, y):\n",
    "    for features, label in data:\n",
    "        X.append(features)\n",
    "        if label == \"f\":\n",
    "            y.append([1, 0])\n",
    "        elif label == \"m\":\n",
    "            y.append([0, 1])\n",
    "        else:\n",
    "            y.append([1, 1])\n",
    "\n",
    "            \n",
    "# prepare_Xy_binary(training_data, X_train, y_train)\n",
    "# prepare_Xy_binary(test_data, X_test, y_test)\n",
    "\n",
    "prepare_Xy_ternary(training_data, X_train, y_train)\n",
    "prepare_Xy_ternary(test_data, X_test, y_test)\n",
    "\n",
    "# prepare_Xy_binary_multi_label(training_data, X_train, y_train)\n",
    "# prepare_Xy_binary_multi_label(test_data, X_test, y_test)\n",
    "\n",
    "print(X_train[-10:])\n",
    "print(y_train[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107652\n",
      "10845\n",
      "3174\n",
      "[['आ', ['VM', 'any']], ['आ', ['VM', 'm']], ['कर', ['VM', 'm']], ['कर', ['VM', 'any']], ['लग', ['VM', 'any']], ['लग', ['VM', 'm']], ['डर', ['VM', 'any']], ['डर', ['NN', 'm']], ['मेरे', ['PRP', 'any']], ['मेरे', ['PRP', 'm']]]\n",
      "107652\n",
      "10845\n",
      "['र ख े', 'ख ं भ े', 'व ् य व स ् थ ा', 'ज ि स क ी', 'म ह ि ल ा', 'ज ा र ी', 'ग ि र ो ह', 'उ त ् प ा द न', 'ब द ल ा व', 'प ह ु ं च ा']\n"
     ]
    }
   ],
   "source": [
    "# dataset analysis\n",
    "print(len(training_data))\n",
    "print(len(test_data))\n",
    "print(len(exceptions))\n",
    "\n",
    "print(exceptions[:10])\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(X_train[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(oov_token = \"<oov>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "# tokenizer.fit_on_texts(X_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "# print(word_index)\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "# create sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "max_length = 0\n",
    "for s in X_train_seq:\n",
    "    if max_length < len(s):\n",
    "        max_length = len(s)\n",
    "for s in X_test_seq:\n",
    "    if max_length < len(s):\n",
    "        max_length = len(s)\n",
    "    \n",
    "max_length = 20\n",
    "        \n",
    "# padding\n",
    "X_train_padded = pad_sequences(X_train_seq, padding = \"post\", maxlen = max_length)\n",
    "X_test_padded = pad_sequences(X_test_seq, padding = \"post\", maxlen = max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 64)            5888      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 566,019\n",
      "Trainable params: 566,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# simple binary classification models\n",
    "embedding_dim = 64\n",
    "\n",
    "def model_64_binary():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def model_512_binary():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# ternary classification models\n",
    "# 64 (4 layers) not sufficient (though gives upto 91% accuracy in 100 epochs)\n",
    "def model_64_ternary():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "\n",
    "#         tf.keras.layers.Dense(2, activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def model_512_ternary():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "\n",
    "#         tf.keras.layers.Dense(2, activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def model_64_binary_multi_label():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.005)),\n",
    "\n",
    "        tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def model_512_binary_multi_label():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "#                      kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "\n",
    "        tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def compile_binary():\n",
    "    model = model_64_binary()\n",
    "#     model = model_512_binary()\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def compile_ternary():\n",
    "#     model = model_64_ternary()\n",
    "    model = model_512_ternary()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def compile_binary_multi_label():\n",
    "    model = model_64_binary_multi_label()\n",
    "#     model = model_512_binary_multi_label()\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    return model\n",
    "    \n",
    "model = compile_ternary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(\n",
    "#     model, show_shapes=True, show_layer_names=True, expand_nested=True, dpi=64\n",
    "# #     model, to_file=dot_img_file, show_shapes=True, show_layer_names=True,\n",
    "# #     rankdir='TB', expand_nested=False, dpi=96\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/3365 [..............................] - ETA: 0s - loss: 1.0987 - accuracy: 0.3125WARNING:tensorflow:From /home/yash/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0044s vs `on_train_batch_end` time: 0.0098s). Check your callbacks.\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.7231 - accuracy: 0.7056 - val_loss: 0.5725 - val_accuracy: 0.7828\n",
      "Epoch 2/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.5679 - accuracy: 0.7822 - val_loss: 0.4618 - val_accuracy: 0.8322\n",
      "Epoch 3/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.4756 - accuracy: 0.8251 - val_loss: 0.3803 - val_accuracy: 0.8624\n",
      "Epoch 4/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.4180 - accuracy: 0.8492 - val_loss: 0.3372 - val_accuracy: 0.8758\n",
      "Epoch 5/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.3800 - accuracy: 0.8643 - val_loss: 0.3040 - val_accuracy: 0.8928\n",
      "Epoch 6/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.3510 - accuracy: 0.8748 - val_loss: 0.2899 - val_accuracy: 0.8984\n",
      "Epoch 7/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.3325 - accuracy: 0.8826 - val_loss: 0.2874 - val_accuracy: 0.9021\n",
      "Epoch 8/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.3145 - accuracy: 0.8888 - val_loss: 0.2636 - val_accuracy: 0.9073\n",
      "Epoch 9/100\n",
      "3365/3365 [==============================] - 12s 3ms/step - loss: 0.3010 - accuracy: 0.8952 - val_loss: 0.2410 - val_accuracy: 0.9169\n",
      "Epoch 10/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2860 - accuracy: 0.9009 - val_loss: 0.2337 - val_accuracy: 0.9175\n",
      "Epoch 11/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2775 - accuracy: 0.9038 - val_loss: 0.2252 - val_accuracy: 0.9271\n",
      "Epoch 12/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2658 - accuracy: 0.9086 - val_loss: 0.2236 - val_accuracy: 0.9265\n",
      "Epoch 13/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2598 - accuracy: 0.9104 - val_loss: 0.2128 - val_accuracy: 0.9285\n",
      "Epoch 14/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2515 - accuracy: 0.9125 - val_loss: 0.2100 - val_accuracy: 0.9296\n",
      "Epoch 15/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2443 - accuracy: 0.9155 - val_loss: 0.2022 - val_accuracy: 0.9351\n",
      "Epoch 16/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.2384 - accuracy: 0.9180 - val_loss: 0.2046 - val_accuracy: 0.9339\n",
      "Epoch 17/100\n",
      "3365/3365 [==============================] - 12s 3ms/step - loss: 0.2328 - accuracy: 0.9202 - val_loss: 0.1908 - val_accuracy: 0.9385\n",
      "Epoch 18/100\n",
      "3365/3365 [==============================] - 12s 3ms/step - loss: 0.2283 - accuracy: 0.9217 - val_loss: 0.1909 - val_accuracy: 0.9345\n",
      "Epoch 19/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2224 - accuracy: 0.9230 - val_loss: 0.1914 - val_accuracy: 0.9371\n",
      "Epoch 20/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2207 - accuracy: 0.9247 - val_loss: 0.1846 - val_accuracy: 0.9410\n",
      "Epoch 21/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2169 - accuracy: 0.9259 - val_loss: 0.1837 - val_accuracy: 0.9427\n",
      "Epoch 22/100\n",
      "3365/3365 [==============================] - 12s 3ms/step - loss: 0.2118 - accuracy: 0.9275 - val_loss: 0.1785 - val_accuracy: 0.9412\n",
      "Epoch 23/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2089 - accuracy: 0.9282 - val_loss: 0.1799 - val_accuracy: 0.9438\n",
      "Epoch 24/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2045 - accuracy: 0.9299 - val_loss: 0.1742 - val_accuracy: 0.9447\n",
      "Epoch 25/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2007 - accuracy: 0.9307 - val_loss: 0.1810 - val_accuracy: 0.9428\n",
      "Epoch 26/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.2007 - accuracy: 0.9313 - val_loss: 0.1794 - val_accuracy: 0.9436\n",
      "Epoch 27/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1951 - accuracy: 0.9337 - val_loss: 0.1748 - val_accuracy: 0.9458\n",
      "Epoch 28/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1939 - accuracy: 0.9334 - val_loss: 0.1786 - val_accuracy: 0.9424\n",
      "Epoch 29/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1905 - accuracy: 0.9334 - val_loss: 0.1746 - val_accuracy: 0.9445\n",
      "Epoch 30/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1877 - accuracy: 0.9356 - val_loss: 0.1699 - val_accuracy: 0.9448\n",
      "Epoch 31/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1869 - accuracy: 0.9366 - val_loss: 0.1733 - val_accuracy: 0.9453\n",
      "Epoch 32/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1845 - accuracy: 0.9360 - val_loss: 0.1659 - val_accuracy: 0.9457\n",
      "Epoch 33/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1793 - accuracy: 0.9378 - val_loss: 0.1710 - val_accuracy: 0.9471\n",
      "Epoch 34/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1809 - accuracy: 0.9382 - val_loss: 0.1744 - val_accuracy: 0.9477\n",
      "Epoch 35/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1785 - accuracy: 0.9391 - val_loss: 0.1731 - val_accuracy: 0.9484\n",
      "Epoch 36/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1763 - accuracy: 0.9398 - val_loss: 0.1648 - val_accuracy: 0.9484\n",
      "Epoch 37/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1752 - accuracy: 0.9402 - val_loss: 0.1676 - val_accuracy: 0.9495\n",
      "Epoch 38/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1721 - accuracy: 0.9411 - val_loss: 0.1578 - val_accuracy: 0.9502\n",
      "Epoch 39/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1735 - accuracy: 0.9404 - val_loss: 0.1652 - val_accuracy: 0.9466\n",
      "Epoch 40/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1695 - accuracy: 0.9422 - val_loss: 0.1652 - val_accuracy: 0.9484\n",
      "Epoch 41/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1683 - accuracy: 0.9429 - val_loss: 0.1709 - val_accuracy: 0.9483\n",
      "Epoch 42/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1673 - accuracy: 0.9420 - val_loss: 0.1697 - val_accuracy: 0.9486\n",
      "Epoch 43/100\n",
      "3365/3365 [==============================] - 14s 4ms/step - loss: 0.1675 - accuracy: 0.9433 - val_loss: 0.1632 - val_accuracy: 0.9491\n",
      "Epoch 44/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1662 - accuracy: 0.9434 - val_loss: 0.1705 - val_accuracy: 0.9482\n",
      "Epoch 45/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1644 - accuracy: 0.9434 - val_loss: 0.1709 - val_accuracy: 0.9492\n",
      "Epoch 46/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1633 - accuracy: 0.9436 - val_loss: 0.1631 - val_accuracy: 0.9521\n",
      "Epoch 47/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1625 - accuracy: 0.9444 - val_loss: 0.1650 - val_accuracy: 0.9503\n",
      "Epoch 48/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1609 - accuracy: 0.9449 - val_loss: 0.1655 - val_accuracy: 0.9489\n",
      "Epoch 49/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1602 - accuracy: 0.9448 - val_loss: 0.1630 - val_accuracy: 0.9490\n",
      "Epoch 50/100\n",
      "3365/3365 [==============================] - 15s 4ms/step - loss: 0.1592 - accuracy: 0.9459 - val_loss: 0.1617 - val_accuracy: 0.9502\n",
      "Epoch 51/100\n",
      "3365/3365 [==============================] - 16s 5ms/step - loss: 0.1556 - accuracy: 0.9470 - val_loss: 0.1702 - val_accuracy: 0.9470\n",
      "Epoch 52/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1566 - accuracy: 0.9468 - val_loss: 0.1732 - val_accuracy: 0.9499\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1581 - accuracy: 0.9467 - val_loss: 0.1626 - val_accuracy: 0.9520\n",
      "Epoch 54/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1560 - accuracy: 0.9471 - val_loss: 0.1620 - val_accuracy: 0.9510\n",
      "Epoch 55/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1542 - accuracy: 0.9476 - val_loss: 0.1602 - val_accuracy: 0.9509\n",
      "Epoch 56/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1548 - accuracy: 0.9468 - val_loss: 0.1640 - val_accuracy: 0.9512\n",
      "Epoch 57/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1522 - accuracy: 0.9490 - val_loss: 0.1596 - val_accuracy: 0.9550\n",
      "Epoch 58/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1529 - accuracy: 0.9477 - val_loss: 0.1676 - val_accuracy: 0.9496\n",
      "Epoch 59/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1526 - accuracy: 0.9483 - val_loss: 0.1581 - val_accuracy: 0.9502\n",
      "Epoch 60/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1490 - accuracy: 0.9492 - val_loss: 0.1596 - val_accuracy: 0.9517\n",
      "Epoch 61/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1496 - accuracy: 0.9493 - val_loss: 0.1601 - val_accuracy: 0.9518\n",
      "Epoch 62/100\n",
      "3365/3365 [==============================] - 16s 5ms/step - loss: 0.1485 - accuracy: 0.9499 - val_loss: 0.1635 - val_accuracy: 0.9545\n",
      "Epoch 63/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1481 - accuracy: 0.9493 - val_loss: 0.1661 - val_accuracy: 0.9539\n",
      "Epoch 64/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1478 - accuracy: 0.9494 - val_loss: 0.1629 - val_accuracy: 0.9522\n",
      "Epoch 65/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1461 - accuracy: 0.9505 - val_loss: 0.1635 - val_accuracy: 0.9546\n",
      "Epoch 66/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1472 - accuracy: 0.9503 - val_loss: 0.1660 - val_accuracy: 0.9520\n",
      "Epoch 67/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1451 - accuracy: 0.9507 - val_loss: 0.1657 - val_accuracy: 0.9535\n",
      "Epoch 68/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1434 - accuracy: 0.9513 - val_loss: 0.1651 - val_accuracy: 0.9561\n",
      "Epoch 69/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1433 - accuracy: 0.9514 - val_loss: 0.1593 - val_accuracy: 0.9556\n",
      "Epoch 70/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1458 - accuracy: 0.9511 - val_loss: 0.1592 - val_accuracy: 0.9544\n",
      "Epoch 71/100\n",
      "3365/3365 [==============================] - 14s 4ms/step - loss: 0.1421 - accuracy: 0.9518 - val_loss: 0.1686 - val_accuracy: 0.9537\n",
      "Epoch 72/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1424 - accuracy: 0.9520 - val_loss: 0.1673 - val_accuracy: 0.9540\n",
      "Epoch 73/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1432 - accuracy: 0.9515 - val_loss: 0.1722 - val_accuracy: 0.9544\n",
      "Epoch 74/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1430 - accuracy: 0.9514 - val_loss: 0.1612 - val_accuracy: 0.9543\n",
      "Epoch 75/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1389 - accuracy: 0.9530 - val_loss: 0.1706 - val_accuracy: 0.9538\n",
      "Epoch 76/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1409 - accuracy: 0.9524 - val_loss: 0.1653 - val_accuracy: 0.9531\n",
      "Epoch 77/100\n",
      "3365/3365 [==============================] - 14s 4ms/step - loss: 0.1398 - accuracy: 0.9528 - val_loss: 0.1704 - val_accuracy: 0.9541\n",
      "Epoch 78/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1382 - accuracy: 0.9536 - val_loss: 0.1688 - val_accuracy: 0.9538\n",
      "Epoch 79/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1382 - accuracy: 0.9532 - val_loss: 0.1727 - val_accuracy: 0.9521\n",
      "Epoch 80/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1386 - accuracy: 0.9531 - val_loss: 0.1713 - val_accuracy: 0.9516\n",
      "Epoch 81/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1394 - accuracy: 0.9529 - val_loss: 0.1626 - val_accuracy: 0.9541\n",
      "Epoch 82/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1374 - accuracy: 0.9539 - val_loss: 0.1688 - val_accuracy: 0.9565\n",
      "Epoch 83/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1400 - accuracy: 0.9529 - val_loss: 0.1678 - val_accuracy: 0.9556\n",
      "Epoch 84/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1355 - accuracy: 0.9542 - val_loss: 0.1732 - val_accuracy: 0.9544\n",
      "Epoch 85/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1347 - accuracy: 0.9544 - val_loss: 0.1705 - val_accuracy: 0.9540\n",
      "Epoch 86/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1341 - accuracy: 0.9546 - val_loss: 0.1647 - val_accuracy: 0.9553\n",
      "Epoch 87/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1336 - accuracy: 0.9549 - val_loss: 0.1622 - val_accuracy: 0.9514\n",
      "Epoch 88/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1361 - accuracy: 0.9541 - val_loss: 0.1583 - val_accuracy: 0.9568\n",
      "Epoch 89/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1321 - accuracy: 0.9547 - val_loss: 0.1667 - val_accuracy: 0.9553\n",
      "Epoch 90/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1355 - accuracy: 0.9545 - val_loss: 0.1693 - val_accuracy: 0.9535\n",
      "Epoch 91/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1333 - accuracy: 0.9554 - val_loss: 0.1730 - val_accuracy: 0.9535\n",
      "Epoch 92/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1329 - accuracy: 0.9554 - val_loss: 0.1692 - val_accuracy: 0.9545\n",
      "Epoch 93/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1327 - accuracy: 0.9551 - val_loss: 0.1716 - val_accuracy: 0.9538\n",
      "Epoch 94/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1328 - accuracy: 0.9550 - val_loss: 0.1753 - val_accuracy: 0.9560\n",
      "Epoch 95/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1315 - accuracy: 0.9556 - val_loss: 0.1752 - val_accuracy: 0.9551\n",
      "Epoch 96/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1314 - accuracy: 0.9554 - val_loss: 0.1721 - val_accuracy: 0.9560\n",
      "Epoch 97/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1309 - accuracy: 0.9554 - val_loss: 0.1656 - val_accuracy: 0.9560\n",
      "Epoch 98/100\n",
      "3365/3365 [==============================] - 13s 4ms/step - loss: 0.1302 - accuracy: 0.9561 - val_loss: 0.1717 - val_accuracy: 0.9568\n",
      "Epoch 99/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1308 - accuracy: 0.9562 - val_loss: 0.1624 - val_accuracy: 0.9557\n",
      "Epoch 100/100\n",
      "3365/3365 [==============================] - 12s 4ms/step - loss: 0.1324 - accuracy: 0.9554 - val_loss: 0.1671 - val_accuracy: 0.9571\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/\n",
    "\n",
    "\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# earlystopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "history = model.fit(np.array(X_train_padded), np.array(y_train),\n",
    "                epochs = num_epochs,\n",
    "#                 batch_size = 128,\n",
    "                validation_data = (np.array(X_test_padded), np.array(y_test)),\n",
    "                verbose = 1,\n",
    "                callbacks=[tensorboard_callback]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9723), started 1 day, 22:13:48 ago. (Use '!kill 9723' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-21a0bc6dd65eaa26\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-21a0bc6dd65eaa26\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch TensorBoard and navigate to the Profile tab to view performance profile\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7AklEQVR4nO3dd3gd1Zn48e+r3pstV9m494ILNtUUUwzYtFAcSsChLFlgCewGCCHBLPllSQjJwkJwIIBxaCGmEzBgmhMMuPfeJRd1yerSvff9/TEj+Uq+kq9sXV9bej/Po0eamXNmzsjyvPeUOUdUFWOMMaapiHAXwBhjzLHJAoQxxpiALEAYY4wJyAKEMcaYgCxAGGOMCcgChDHGmIAsQBhjEBEVkQHhLoc5tliAMMYYE5AFCGOCJI5j7v+MiESFuwymfTrm/tiNaYmIPCAiW0WkTETWicjlTY7fKiLr/Y6Pdff3EpG3RSRfRApF5Gl3/0wRecUvfx+3uSXK3f5KRP6fiHwDVAL9RGSG3zW2ici/NSnDpSKyQkT2u2WdIiJXicjSJun+U0TebeY++4rIAvca80Xkmfpy+pXxZhHZBXzh7v+7iOwTkVI373C/880WkVki8pl7zq9F5IQmlz1XRDaLSLF7PWnFP41phyxAmOPNVuAMIBV4BHhFRLoDiMhVwEzgR0AKcAlQKCKRwIfATqAP0BN4oxXXvAG4DUh2z5EHTHWvMQP4o18gmgDMAX4GpAGTgB3A+0BfERnqd97rgb82c83XgEVAJ/eebgiQ5kxgKHCBu/0xMBDoAiwDXm2S/jrgUaAzsCLA8anAScBo4Gq/85oOSmwuJnM8E5EVwMOq+p6IfAJ8pKpPNklzCs4DuruqepocmwkMUNXr3e0+wHYgWlU9IvIVsEBVf9VCGd4FvlTVJ0Xkz0Clqt4TIN2zQJGq/sL9dP8voJuq1jRJ1xvYBqSoaqW77xUAVb3er4z9VXVbM2VKA4qBNFUtFZHZQJyqTnePJwGlQB9VzRYRBc5Q1X+5x98ElqnqY83dt2n/rAZhjisi8iO3+aZEREqAETifiAF64dQwmuoF7GwaHFohu0kZLhSR70SkyC3DRUGUAeBl4Fq36eYG4M2mwcHVAyeQVDZXhqb7RCRSRB5zm7T249Ra8CtXo/SqWg4Uudeqt8/v50ogqZn7MB2EBQhz3HDbzJ8H7gQ6qWoasAaobyvPBvoHyJoN9G6mM7cCSPDb7hYgTUM1W0RigbeA3wNd3TJ8FEQZUNXvgFqcJrJrab55aS+QISL+5erVUrnc810KnIvT/NanvsiBzuHWIDKAPc2UwRgLEOa4kojzUMwHEJEZODWIen8B/ktExrkjjga4QWURzkP3MRFJFJE4ETnNzbMCmCQivUUkFfj5IcoQA8S6ZfCIyIXA+X7HXwBmiMhkEYkQkZ4iMsTv+BzgacBT35zTlKruBJYAM0Ukxm0im3aIciUDNUAhTsD7TYA0F4nI6SISg9MX8b2qBqqZGANYgDDHEVVdBzwBfAvkAiOBb/yO/x34fzgdvGXAu0CGqnpxHrADgF1ADnCNm+cz4G/AKmApTmd2S2UoA/4DeBOnjf9anP6N+uOLcDuucdr4vwb8Rwv9FSeoNVd7qHcdcArOA//XbhkDNUfVm4PTgb4bWAd8FyDNa8DDOE1L49xrGNMs66Q25igSkXicUVBjVXVzK/L9Ddigqg8f5nVnAzmq+tDh5Dcdk9UgjDm6fgIsPlRwEJGTRKS/20w1Bad/4d2jUUBj6tkbmMYcJSKyA6fT+LIgkncD3sZ5DyIH+ImqLg9Z4YwJwJqYjDHGBGRNTMYYYwJqV01MnTt31j59+oS7GMYYc9xYunRpgapmBjrWrgJEnz59WLJkSbiLYYwxxw0R2dncMWtiMsYYE5AFCGOMMQFZgDDGGBOQBQhjjDEBWYAwxhgTkAUIY4wxAVmAMMYYE5AFCGOMCVZdFexZDkd7iiJPrXPd3LWNr11XDeveg3/9MSSXbVcvyhljjpKyXPj6MeeBmZrlfPUcB11HgMih8x8tqrD+ffjsV+DzQc+xkDUe+p4J3UY2X1ZVUB9ERDbeN/dm2PgPyOgP426CE6+DxE5Nsiq5+2uo8/rw+pyHeUp8NGnx0UREuNcr3Q3fz8IXl0Zhp7FsiR5EZFUxnYuWkVa4jKjaUjcOKBRtJ7F4HVG+WgCKIzJYHjOOqMgIJlb/i1hvBZ7knkSe/O9IVGyb/vosQBhzPPHUwsf3QXJ3OOv+1ucv2QUb50Fab8gcDGknQESThoSyfbDiVRh5lZPOnyqsetMpQ10VJHWB/XtAvc7x1N4w+ELoO8l5AKf1PvAQ9nmhsgjKc6F8H9RWQGQMREZDTBKk9HTuKzLAY0kVKvIhJhGiE4ILQkXb4aOfwZbPoOtI6DwAcpbCuned4xn9qBo4ld0pYyiOSKdAU4ko2UGPPZ/SJ+9z6iSap3v9gc016QBcH/U5F2z/B0WDrkELt9Dps19SN/9RVmdcwIqsaymI78eaPftZlVNCSWUdUXgYLVsZFbGNPdqZddoHX3wGM+QDrve+SxReovCSCaRrBFHiA6BCYynQ1IbbyCWdFb7z2BYzmG7xXk7yLGdizbeIevnQexLveE9jXdlolkbGHPp30krtajbX8ePHq021Ydqtump480ew+RNne/prMOTi4POvehP+8Z9Qs//AvtgUGD0dJtwGGf1g8V/gi187aWKS4cLHnE/JqrDjn7DwKdgyH7ImwKXPQOYg8Hpg/27Y/jVs/Bi2fgmeKuf8cakQlwZVJVBTesgiqkRQk9AD7TqCuF6jkaSukP09un0BUrYXAI9EUxqRxqqUs9l0wnQSuvYnPiaK6EghJjKC+Egf/bbMJmvlk3iI4u20G3m8aBLJCXGc0r8TZ/bwkbB9Pinb/8GImhUND+Z6NRrNAt8oJkRsoDIigYfTf0ekp5I/lv6U73zDmFH3M5QIBkXkcGvs50zVL4mnlu99Q/DEppMaH01GdC1dSlYS5a1qdG4fEUTgY3nKObzf+VaSU9MZKxvpX7MBX0JnCtLHkJ84CI9EIggi0CkxhkFdk0lP9AsAPi+ojxqNYNO+cnL3V3PusK7B/y34EZGlqjo+4LFQBgh3oZMngUjgL6r6WJPj6cCLOIu8VwM/VtU17rEdOMtGenHW7w14A/4sQJiQ2vQp5K6GsTcd1Kxw2GorYP0HkJgJWSdBXErz6d64FrZ9DRc9Dsv/6tQGfrIQUnocnL6qBPLWgbcWvHWw8g1YMxd6nQxT/+CcL38DbP+n84naWwvJPaBsD/Q7G06/B77+Hez8l9McU5oNRduch/2Z98HE2xs3v/irq4LctVRlL6d8xzJqK8soj0ihlCRqYlJJ6tST9K69SE/vRGyEjxg87Mndx6KVq8ndtYUs3cNQ2UU/2UuEKIWk8o13GMt9A4jGQ6fISkbG5jGhbhER6uNL34ks9Q1ih3alkljui3qTYRE7+dh7EjPrbiQ6vSen9OtEcWUt328roqzGA8DQ7ilMGxjHxJQi0rWYFE8RMUmdiBh8PnGJqUTlroQ5l0FsMsQkoZUFrLnkI3bXJdOncyJ9OiUSFx0JFYXokhdh/QeIzzk3kdEHmrKyTnJqWftWQeEWGHoJ9J54hH84bScsAUJEIoFNwHk4C54sBn7oritcn+ZxoFxVH3EXdn9GVSe7x3YA41W1INhrWoDo4LyewM0TR3zeOpg/E7592tmOiodxN8Ipd0Jar5bz+nwHN+EAeGpg6WxY8HuoyHP2SQR0He42s8RARJTzsK0qdh7Q5bnOp/YTr4WCzfDnSc5D6Ib3nGt4PbD9K1jxGqz/ELx+S1hLJJz1c+fB3/R3VJ4Py2bD9gUwbgal/aayLLuESJR+W+fQfcWTVKYPYVvvq1mVPInNxR425ZaxJa+CihoPHp+POq8SFx1Banw0KXHRlFTVkV/W0hLaB4uNiuDSE3swZUQ39pRUs3NvPtUle/GlnkBmShzdUuIY0TOVwd2SiY6MgP178C1+EV3xOpFlOQ3nqU3oyraTZrKn+2QGZCbTu1PCgV+718eGfWWkxkfTKyMhUDEa27sS5lzq/Btc+3cYdH6r7ul4EK4AcQowU1UvcLd/DqCq/+OX5h/A/6jqv9ztrcCpqpprAcK0yFML2d87zRp7V8G+1c6D9pyH4LSftq6jtLbC6TSMT3Pa1OupQt56+OBuyFnkNMOMuQG++xOs/rtTze97Boy8Ggae7zzgvbVQttdpatn4MRRthfN/DRNuPXDeHd/AO7dD6S7ocwaceT/46mDXd849VZc6QclbC9HxEJ/ufI26BgZfSK3Hh0+VuNWvwvt3wQmnOw+wws3grUXj0ykfeDnbM06jUuOo9EawT9NZV5HE9oIKCstr6Z2RQP8uSfRKTyBCwKdQWlXHgk35LN5RhMfX/HMhKTaKgV2TGJCZRFpCNFGREURHCNUeH6WVdZRU1ZIUG82ALkkM6JJEVno86QkxpCVEU+f1sbOwkp2FleSVVVPj8VFd5yUlLprLxvQkI/Ew29FryqF4u/NJvffJTtNWWynYAgWbYMhFbXfOY0i4AsSVwBRVvcXdvgGYqKp3+qX5DRCnqveKyARgoZtmqYhsB4oBBf6sqs81c53bgNsAevfuPW7nzmZnrjXHE0+tUx3P3wD5G6E0B+dPAaejc8e/oLbM+WScOdjpEK0qcdrnT7kTznvU+VSdtwGWzXHSRsZARLTzAC7Pdb7273YervUy+kPvU5wH9vYFzsM+Jhku/T8YfvmBdCW7YPmrsPpNp+mlKYmA3qc6Zdi+AMb/GKY85tRCvvg1pPeFi5+Afmc1G8y8PiVCQNzjHq+P1xft4g+fbaLG4+PcIV24r+4ZuhQsoiSxLzlRvVlU1585hUPYU+476Hyp8dH07ZxIRmIMOwsr2FVUSZ238f//wV2TmTy0C2cMzCQ6Uiir9lBe4yE1PprOSbFkJsfSOSmmoUzm+BeuAHEVcEGTADFBVe/yS5OC00cxBlgNDAFuUdWVItJDVfeISBfgM+AuVV3Q0jWtBnEcqyiAte84NYL8jVC49cDIGASSuzlNLgBRcdDndBh4njNaJjbZ2e/zwbz7YdFzMOwyqC13OlQjYyEh40B7fGyKU1NI6uKMnKkfplm21/kUv+tbJ/D0neR8DZoCKd0Dl1sV9iyD7MVOm3xkjPPpte8k55o+LzWfPkLsd09SEZVOoqeYzV0uYNGIh4mIc5pKoiKEkspaCspryS+rIafE+YS9p6SKjMRYTuyVxvAeKXy8Zi+bcss5uV8GfTsnMW/NXoor6xoVp1dGPON6pzOuTwZDuiWTGBNFQkwkqfHRjTs5cQJOfrnTDBQhTgdv0zSm/Ttmm5iapBdgOzBKVfc3OTYTp6/i9y1d0wJEGFQUOiNfBp0PPcYcOn1dFRTvcJp06j/F71wIW79wAkJ6H2csfeYQp2aQOQQ6D3SaWoKhCl//Fr76H0jsAhNvg3E/bl2nsuoRjeVXVTbmlvH5+jy+3JDH8uwSpvJP7ot+k2c9l/CKdzJw8PkjI4SMxBh6psVzQqcEstLj2VtazYrsErblV9A7I4EHLxrKBcO7IiLUeX0s3FpISWUt/TOT6Ns5kcRYG7luWidcASIKp5N6MrAbp5P6WlVd65cmDahU1VoRuRU4Q1V/JCKJQISqlrk/fwb8t6rOa+maFiDaSPV+yFnsfJIu2AzDLnW+/EeteGph0Z/h68ed4YtR8XDlCweGXdZWwJIXnTc/q4rdjtbdsD/n4Oul9oaRP3DG3Xcd3jb3kLfeGbbZxi8Oebw+tuZXsHZPKRtzy9hRUMGOgkoKymuIjYogPiaSihov+/ZXAzCiZwpnDspk0sBMxp6QTlSEUOPxUV7joc7rw+NV6rw+5xN+QsyBF6maKKuuIz46kqhIm/zAtK2WAkTIPm6oqkdE7gQ+wRnm+qKqrhWR293js4ChwBwR8QLrgJvd7F2Bd9x2zijgtUMFB9NKnhqnWSe154F9dVXw5W+cTlifx2lHT+jkDIPM6A8T/81Js2+V0xSzfzcMOM8ZGfPpQ/DGdU47e1QsfPWY8zJUaq8Dnax9Tnce2hn9nNE/SV2dZp6YxLa/vy5DG22qKntKq9mcW0aX5DgGd0smMkJQVVbllPLpun3kFFdRU+ej2uNteAMWoNZ9oJfXeNhX6nSsAsRERtArI56+nRMZ3yedGo+PqjovESKc1r8TZw/pQteUuIOKFhcd6QyPbIXkuOjD+CUYc2TsRbmOprIIlrwAi553mneyJsD4GU5b/D/udTqGT7weRl7pDKGMToANH8I//wB7VzjnSO3tdAqP/zEMPNfZV1sBb90CGz9ytntNhPP+2xlREiY+n/LlxjxmL9zBiuwSyqo9DccSYyIZlZXGzsIK9pRWExkhZKXHExcVSWx0BJF+n+SjIyJIjosiKS6KzKRYhvVIYUTPVPp1TrRP9Oa4F7YX5Y42CxCHsOh5+PSXzluu/Sc7o3VW/c0ZHgnOg/+Sp6D/2QfnVXU6j5O6OJ2vgfi88P0spx9h8EUhnZOnzusjr6yGXYWVLNlRxKIdRazfW0bvjHhG9kwlKz2BuUtz2JhbRs+0eM4eksngbikM7JLEvtJqlu4sZmVOCV2S47hwRDcmD+1CWoJ10JqOxwKEgYX/5zQDDTjP+WTfdZizXxV2fuO02Y+efmBE0DHC61M27itjeXYxm/aVsSm3nK355eSX1zSa1HJw12SG90whp6iKNXtKqaz1MrBLEj85qz/TRvdwXqwyxhwkLH0Q5ijy+eCj/3T6DKb89uA3Zb950pnNcthl8IO/ONMA1BNx+gb6nH5UixxI7v5qvt9eRN7+anL3V7M1v4LFO4oamoYSYyIZ1C2ZMwdl0j0tnu6pcXRPjePEXmmNPv17fcq+/dV0T4lrttPXGHNoFiDagy/+2xkxBM4IpMtnOSOOPDXOS1kLn4LhV8AVz4dmKopWqK7zsmxXMRU1Xk7olEDvjAS25JXzwr+288HKPQ1v8MZFR9ArPYGpo7ozoW8G43pnkJUeH9QDPzJC6JkW5LBYY0yzLEAcbyoKnVFCsUnO9vJXnMVCxs1wRiR98WsnOIy/Gd6/03kTedxNcNETYQsONR4vr3+/i4/X7GN5dgm1noPf8k2MieSGU07gB2Oz6JWRQEpclL2ta0yYWYA4npTmwKzTnRFDfc90RhkteNyZffOix52mI58PvvoNrHzdmZ3zurnOG8chVF7jwetTkmOjGn3CV1U+Wr2P387bwK6iSoZ2T+HGU07glP6dyEiMZVdRJTsLKkiKi+KKsVmkxttQTmOOJRYgjhc+nzPBm6fWGV666RNnIZTOg+Gq2Qf6Fc6636ldlObAWQ+07aRlTVTXefnTV1uZ9dVWar0+IsSZ7yc2KhIRqPMqBeU1DOmWzMs/nsCZgzIb5T+xV1rIymaMOXIWII4X3/6fs2DLJU/D2BucF9IKt0BiZ2cWUn+n3BGyYqgqRRW1LN5RxG8+cmoG00b3YHRWKqVVdRRX1lLnURTFpzChbwY/GJvV6L0CY8zxwQLE8WDvSvj8URg6DcZc7+wTceYoCvWlS6tYurOYZTtLWJlTwpa8ckqrnAni+mUm8totEzl1QOeQl8MYc/RZgDhW1ZQ701ls/xpWz3VqCtOeOioLwnu8Puavz2POtztYuLUQcEYVjeqZxrTR3enbOYn+mYmc0r8TsVGtmzLCGHP8sABxrKkqhm+ect5Irqt01i/oNQHOfaT5N5iPUI3Hy+LtxazbW8r6vWV8v62QPaXV9EiN47/OH8SkQZkM7Z5iL5sZ08FYgAinkmx4fbrTkZzR11mYZsVrzoLxI65wFovvfQrEBLE04mHYll/OG4uzmbs0h6KKWoCGZR1/NW045w7tYnMNGdOBWYAIp8V/caa46DUBNn/mTJ43+GI45xdtN+11E1vzy5m3Zh+frt3HypxSoiKE84Z15cpxWYzpnX74Sz4aY9odCxDh4qmB5X+FwRfC9FedfV5PSF5mq67z8o9Ve5nz7Q5W5pQCMLpXGg9cOIQrxvakS/LBU1IbY4wFiHBZ/wFUFjrvNNRrw+CgqqzZvZ/3Vuzm7eW7KaqopX9mIr+aOowLR3aje6pNRWGMaZkFiHBZ/IKzcH2/AFNrH4G9pVW8tTSHt5fvZlt+BdGRwuQhXfmR+wazTV9hjAmWBYhwyFsPuxY6025HHHknsKry1aZ85izcwdeb8vEpTOybwa1n9OOiEd1JTbApLIwxrWcBIhyWvAiRMc7KbUdo2a5iHvt4A4u2F9E1JZZ/P2sAV43P4oROIVjG0xjToViAOFpUneU+C7fAyjectRkSOx326fLKqnnkg3X8Y9VeOifF8uhlI5h+Ui97V8EY02YsQBwNOUuc9x0q8p3tiGiY+G+HdSpV5d0Vu3nkg3VU1nr56bkDufWMfiTG2j+lMaZt2VPlaPjnE04N4oL/gYx+znKfab1bfZriilp+NncV89fnMrZ3Gr+7cjQDuiSFoMDGGGMBIvRKsmHTPDj9Xjjl3w/7NMt2FXPnq8soKK/loYuHMuO0vjZDqjEmpCxAhNqyOU7tYdyNh5W9zuvjpW+287t5G+mWGsfcn5zCqKy0ti2jMcYEYAEilLx1ToAYeH6rm5R8PuWDVXv442eb2FFYyXnDuvL7K0fbkFVjzFFjASKUNn4E5fvgpKeCzuL1KR+v2cszX25l/d79DOmWzIs3jefswV3sJTdjzFFlASKUFr8Aqb1gwLmHTKqq/H1JDs98tYWdhZX065zI/15zIpeM7tFonWdjjDlaLECESsEWZ7Gfcx6CiEMvqvP8P7fxm482MCorlVnXj+W8Yd2sE9oYE1YWIELB54N5D0BkLIz50SGTf7Uxj8c+3sDFI7vz9LVjrCnJGHNMsAARCgufgi2fwcVPQHLXFpNuzS/nrteXM7hbCo9fNcqCgzHmmGHzMrS1Xd/D5//tTKUx/uYWk+4rrebWOUuIjozg+R+NIyHG4rUx5tgR0gAhIlNEZKOIbBGRBwIcTxeRd0RklYgsEpERweY9JlUWwdwfQ1ovuOQpaKE28Pn6XC58cgF7S6p59rqxZKWHZllRY4w5XCELECISCTwDXAgMA34oIsOaJHsQWKGqo4AfAU+2Iu+xpbIIXr3SWTb0ypecdaYDqPP6mPn+Wm5+eQndU+P58D9OZ2K/w5+0zxhjQiWUNYgJwBZV3aaqtcAbwKVN0gwDPgdQ1Q1AHxHpGmTeY0dZLsyeCvtWw9UvQ8+xzSb93/mbmL1wBzNO68M7d5xK/0ybS8kYc2wKZYDoCWT7bee4+/ytBK4AEJEJwAlAVpB5cfPdJiJLRGRJfn5+GxW9FUqy4aUpULwDrvs7DLm42aTLdhXz7FdbuXp8Fg9PG05s1KGHvxpjTLiEMkAEaoDXJtuPAekisgK4C1gOeILM6+xUfU5Vx6vq+MzMzCMo7mHw1MLfroOKQvjRu9DvrGaTVtV6+a83V9I9NZ5fTj22W8uMMQZCO8w1B+jlt50F7PFPoKr7gRkA4ozv3O5+JRwq7zFhwe9g70q45hXoNaHFpL+dt4FtBRW8dstEkuNsPiVjzLEvlDWIxcBAEekrIjHAdOB9/wQikuYeA7gFWOAGjUPmDbvsRc46DydeD0OntZj0u22FzF64g5tO7cOpAzofpQIaY8yRCVkNQlU9InIn8AkQCbyoqmtF5Hb3+CxgKDBHRLzAOuDmlvKGqqytVlMOb98GqVkw5X9aTFrr8fHQu2vISo/n/ilDjlIBjTHmyIX0zSxV/Qj4qMm+WX4/fwsMDDbvMePr3zqd0jM+griUFpO++M12tuSV88KN44mPsU5pY8zxw96kPhyb5sHA8+CEU1tMtrukiifnb+a8YV2ZPLTlKTeMMeZYYwGitSqLoGAT9D75kEkf/WAdivLwNBu1ZIw5/liAaK3s753vvVoOEF9uyGPe2n3cdc5Am0bDGHNcsgDRWru+g4joFt+Wrqjx8NC7axjQJYlbz+h3FAtnjDFtx6YPba3s76H7aIiObzbJE59uYndJFXNvP4WYKIvBxpjjkz29WsNTA7uXtdj/sHxXMS8t3M4NJ5/A+D4ZR7FwxhjTtixAtMbeleCtgV4TAx6u8/r4+dur6Zocx31TBh/lwhljTNuyJqbW2PWd872ZGsRL32xnw74ynv/ReJtOwxhz3LMaRGtkfw/pfSGpy0GHKmo8PPvVViYNyuS8YfbOgzHm+GcBIliqTg2imdrDK9/tpLiyjrsnB3wx3BhjjjsWIIJVtA0qCwL2P1TWenhuwTbOGNiZcSekh6FwxhjT9ixABKuF/odXv9tFYUWt1R6MMe2KBYhgZX/nrDPdufHopKpaL39esJXTBnSyYa3GmHbFRjEFQxW2fQW9T4WIxjH19UW7KCiv5U+TB4WnbMYYEyJWgwhG/kYo2eXM4OpHVXl90S7G9E5jQl+rPRhj2hcLEMHY/KnzfeD5jXavyillc145V4/vFSCTMcYc3yxABGPzp9BlOKQ1DgR/X5pNbFQEF4/qHqaCGWNM6FiAOJTqUtj1LQxqXHuorvPy/oo9TBnRjRR7a9oY0w5ZgDiUrV+AzwMDL2i0e/76XPZXe7hyXFaYCmaMMaFlAeJQNn0KcWmQdVKj3XOX5tA9NY5T+3cOT7mMMSbELEC0xOeDLZ/BgHMh8sCI4Nz91SzYlM8VY3sSGSFhLKAxxoSOBYiW7F0OFfkHjV56Z/lufAo/GGvNS8aY9ssCREs2fQqIU4Pw8+nafYzOSqVfZlJ4ymWMMUeBBYiWbP0CssZDYqeGXeU1HlbmlHL6QOt7MMa0bxYgWlK4GbqNbLRr8fYivD61zmljTLtnAaI51fuhqhjSTmi0e+HWAmIiI2xab2NMu2cBojklO53v6Y0DxDdbChl7Qhpx0ZFhKJQxxhw9FiCaU+wGCL8aRHFFLev27rfmJWNMhxBUgBCRt0TkYhHpOAGloQbRp2HXd9sKAThtQKcAGYwxpn0J9oH/LHAtsFlEHhORISEs07GheCfEJEP8gb6GhVsLSYiJZFRWWvjKZYwxR0lQAUJV56vqdcBYYAfwmYgsFJEZItLsTHUiMkVENorIFhF5IMDxVBH5QERWishaEZnhd2yHiKwWkRUisqT1t3aESnY6/Q9y4E3phVsLmNA3g+jIjlORMsZ0XEE/6USkE3ATcAuwHHgSJ2B81kz6SOAZ4EJgGPBDERnWJNkdwDpVHQ2cBTwhIjF+x89W1RNVdXyw5WwzxTsaNS/l7q9ma34Fp/a35iVjTMcQbB/E28A/gQRgmqpeoqp/U9W7gOZeJ54AbFHVbapaC7wBXNokjQLJIiLueYoAz2HcR9tSdVaQ8+ug/nar0/9gHdTGmI4i2DWpn1bVLwIdaOHTfU8g2287B5jY9LzA+8AeIBm4RlV99acGPhURBf6sqs8FuoiI3AbcBtC7d+8gbiUIFflQV9loiOvCrQWkxkczrHtK21zDGGOOccE2MQ0VkbT6DRFJF5F/P0SeQNOcapPtC4AVQA/gROBpEal/Ap+mqmNxmqjuEJFJgS6iqs+p6nhVHZ+ZmXnIGwlKgCGuq3JKGds7jQibvdUY00EEGyBuVdWS+g1VLQZuPUSeHMB/jc4snJqCvxnA2+rYAmwHhrjX2ON+zwPewWmyOjqavCTn9SnbCioY2DX5qBXBGGPCLdgAEeH2EwANHdAxLaQHWAwMFJG+bsfzdJzmJH+7gMnuObsCg4FtIpIoIsnu/kTgfGBNkGU9csU7nO9pTpNVdlEltR4fA7rY7K3GmI4j2D6IT4A3RWQWTjPR7cC8ljKoqkdE7nTzRgIvqupaEbndPT4LeBSYLSKrcZqk7lfVAhHpB7zjxqQo4DVVbfF6bapkJyRmQkwiAFvyygEsQBhjOpRgA8T9wL8BP8F5kH8K/OVQmVT1I+CjJvtm+f28B6d20DTfNmB0kGVre8U7G/U/bLYAYYzpgIIKEO7Iomfdr/aveEejNai35JXTNSWWlLhm3wk0xph2J9j3IAaKyFwRWSci2+q/Ql24sPB6oDSn0RDXLXllDOxiHdTGmI4l2E7ql3BqDx7gbGAO8NdQFSqs9u8G9TY0MakqW/LKrXnJGNPhBBsg4lX1c0BUdaeqzgTOCV2xwqjJENe9pdVU1HotQBhjOpxgO6mr3am+N7sjk3YDXUJXrDBq8pKcjWAyxnRUwdYgfoozD9N/AOOA64EbQ1Sm8CrZCRIBqVnAgRFMAy1AGGM6mEPWINyX4q5W1Z8B5ThvP7dfxTshJQsinRFLW/LKSE+IplNSbJgLZowxR9chaxCq6gXG+b9J3a7VrwPh2pJXbiOYjDEdUrB9EMuB90Tk70BF/U5VfTskpQqnkmzofzbgjGDanFfORSO7h7lQxhhz9AUbIDKAQhqPXFKgfQUIVagsgERnzYfCilpKKusYkGn9D8aYjifYN6nbd79Dvdpy8NZCghMgNue6HdRdLUAYYzqeoAKEiLzEwWs5oKo/bvMShVOls2ocCc6yolvybYirMabjCraJ6UO/n+OAyzl4bYfjX0WTAJFbRlJsFN1S4sJYKGOMCY9gm5je8t8WkdeB+SEpUTjV1yDcPogt+eX075JERxnAZYwx/oJ9Ua6pgUAbLQB9DGloYsoAYHdxFb0zEsJYIGOMCZ9g+yDKaNwHsQ9njYj2pbLA+e42MeWX1ZBpL8gZYzqoYJuYOsabYpWFEBENsSlU1XqpqPXSOflQK6saY0z7FOx6EJeLSKrfdpqIXBayUoVLZaFTexChoLwGgM5WgzDGdFDB9kE8rKql9RuqWgI8HJIShVNFYUPzUl6ZEyAyky1AGGM6pmADRKB0wQ6RPX5UFjZ0UNfXIKwPwhjTUQUbIJaIyB9EpL+I9BORPwJLQ1mwsKgsbBjiak1MxpiOLtgAcRdQC/wNeBOoAu4IVaHCprKg0QgmgE5J1kltjOmYgh3FVAE8EOKyhJfXA1UlDQGioLyG9IRooiMP91URY4w5vgU7iukzEUnz204XkU9CVqpwqC4BtGGivoKyWmteMsZ0aMF+PO7sjlwCQFWLaW9rUjd5izq/vMZGMBljOrRgA4RPRBqm1hCRPgSY3fW4VtH4LeqC8hqrQRhjOrRgh6r+AviXiHztbk8CbgtNkcKkyUR9BWUWIIwxHVuwndTzRGQ8TlBYAbyHM5Kp/fBbC6Ky1kNFrdeamIwxHVqwk/XdAtwNZOEEiJOBb2m8BOnxrX6ivvgMCvbXAtDZhrgaYzqwYPsg7gZOAnaq6tnAGCA/ZKUKh8oiiEmC6Djyy6sB6Gw1CGNMBxZsgKhW1WoAEYlV1Q3A4NAVKwwqC/1eknNqEDbNhjGmIws2QOS470G8C3wmIu8RxJKjIjJFRDaKyBYROehFOxFJFZEPRGSliKwVkRnB5m1zFQWNRjCBTdRnjOnYgu2kvtz9caaIfAmkAvNayiMikcAzwHlADrBYRN5X1XV+ye4A1qnqNBHJBDaKyKuAN4i8bauyEBIzgQPTbGQkWh+EMabjavU8Eqr6taq+r6q1h0g6AdiiqtvctG8AlzY9HZAszqLPSUAR4Akyb9uqLGo0UV9GYoxNs2GM6dBC+QTsCWT7bee4+/w9DQzFaa5aDdytqr4g8wIgIreJyBIRWZKffwT95pUFTV6Ss9qDMaZjC2WAkAD7mr59fQHOsNkewInA0yKSEmReZ6fqc6o6XlXHZ2ZmHl5JayuhrvLANBv2kpwxxoQ0QOQAvfy2szi4Y3sG8LY6tgDbgSFB5m07VUXO9/qJ+sprrYPaGNPhhTJALAYGikhfEYkBpgPvN0mzC5gMICJdcYbObgsyb9uxeZiMMeYgIVs2VFU9InIn8AkQCbyoqmtF5Hb3+CzgUWC2iKzGaVa6X1ULAALlDVVZ/afZqKjxUFnrtQBhjOnwQrqutKp+BHzUZN8sv5/3AOcHmzdkKt0mpsTO9g6EMca4bBwnNKpBHFiL2kYxGWM6NgsQ4AxxlQiIS214Sc6amIwxHZ0FCHBqEPHpEBFJfrnz/l8Xa2IyxnRwFiDAnajvwEJBIjbNhjHGWIAAqPCbybW8hoyEGKJsmg1jTAdnT0FwaxDOW9S21KgxxjgsQIA7k+uBifo6J1vzkjHGWIBQBfU2mmbDahDGGBPiF+WOCyJw3zYnUAD7q+tIiYsOc6GMMSb8rAZRT5wJZCtqPCTGWtw0xhgLEH5qPF7qvEpynAUIY4yxAOGnosYLQGJMZJhLYowx4WcBwk9FjQfAmpiMMQYLEI2UuwEiyQKEMcZYgPBnNQhjjDnAAoSfcgsQxhjTwAKEn/pOamtiMsYYCxCNHGhislFMxhhjAcKPdVIbY8wBFiD8WB+EMcYcYAHCT0WNh5ioCKJtLQhjjLEA4a+8xmPNS8YY47IA4afCAoQxxjSwAOGnvMZr/Q/GGOOyAOHHqUHYEFdjjAELEI1U1NpaEMYYU88ChJ9yWyzIGGMaWIDwU1HjISnGAoQxxoAFiEYqrJPaGGMaWIBwqSoVtdZJbYwx9UIaIERkiohsFJEtIvJAgOM/E5EV7tcaEfGKSIZ7bIeIrHaPLQllOQEqa72o2jQbxhhTL2RPQxGJBJ4BzgNygMUi8r6qrqtPo6qPA4+76acB96hqkd9pzlbVglCV0Z8tFmSMMY2FsgYxAdiiqttUtRZ4A7i0hfQ/BF4PYXlaVGYzuRpjTCOhDBA9gWy/7Rx330FEJAGYArzlt1uBT0VkqYjc1txFROQ2EVkiIkvy8/MPu7BWgzDGmMZCGSAkwD5tJu004JsmzUunqepY4ELgDhGZFCijqj6nquNVdXxmZuZhF9bWgjDGmMZCGSBygF5+21nAnmbSTqdJ85Kq7nG/5wHv4DRZhYwtN2qMMY2FMkAsBgaKSF8RicEJAu83TSQiqcCZwHt++xJFJLn+Z+B8YE0Iy2rLjRpjTBMh+7isqh4RuRP4BIgEXlTVtSJyu3t8lpv0cuBTVa3wy94VeEdE6sv4mqrOC1VZwZqYjDGmqZA+DVX1I+CjJvtmNdmeDcxusm8bMDqUZWvKOqmNMaYxexq6Kmo8iEBCjDUxGdMW6urqyMnJobq6OtxFMUBcXBxZWVlER0cHnccChKu8xktiTBRus5Yx5gjl5OSQnJxMnz597P9VmKkqhYWF5OTk0Ldv36Dz2VxMrooaj3VQG9OGqqur6dSpkwWHY4CI0KlTp1bX5ixAuMptsSBj2pwFh2PH4fxbWIBwOcuNWoAwxph6FiBcFTUeEm2xIGOMaWABwlVWbU1MxpjD4/F4wl2EkLAnoqui1kNynP06jAmFRz5Yy7o9+9v0nMN6pPDwtOGHTHfZZZeRnZ1NdXU1d999N7fddhvz5s3jwQcfxOv10rlzZz7//HPKy8u56667WLJkCSLCww8/zA9+8AOSkpIoLy8HYO7cuXz44YfMnj2bm266iYyMDJYvX87YsWO55ppr+OlPf0pVVRXx8fG89NJLDB48GK/Xy/33388nn3yCiHDrrbcybNgwnn76ad555x0APvvsM5599lnefvvtNv0dHSl7Irqc5UZtFJMx7c2LL75IRkYGVVVVnHTSSVx66aXceuutLFiwgL59+1JU5MwR+uijj5Kamsrq1asBKC4uPuS5N23axPz584mMjGT//v0sWLCAqKgo5s+fz4MPPshbb73Fc889x/bt21m+fDlRUVEUFRWRnp7OHXfcQX5+PpmZmbz00kvMmDEjpL+Hw2EBwlVeY01MxoRKMJ/0Q+Wpp55q+KSenZ3Nc889x6RJkxreB8jIyABg/vz5vPHGGw350tPTD3nuq666ishI54NlaWkpN954I5s3b0ZEqKurazjv7bffTlRUVKPr3XDDDbzyyivMmDGDb7/9ljlz5rTRHbcdeyICdV4ftR4fSdZJbUy78tVXXzF//ny+/fZbEhISOOussxg9ejQbN248KK2qBhwK6r+v6XsEiYmJDT//8pe/5Oyzz+add95hx44dnHXWWS2ed8aMGUybNo24uDiuuuqqhgByLLFOamweJmPaq9LSUtLT00lISGDDhg1899131NTU8PXXX7N9+3aAhiam888/n6effrohb30TU9euXVm/fj0+n6+hJtLctXr2dNZEmz17dsP+888/n1mzZjV0ZNdfr0ePHvTo0YNf//rX3HTTTW12z23JAgQ2k6sx7dWUKVPweDyMGjWKX/7yl5x88slkZmby3HPPccUVVzB69GiuueYaAB566CGKi4sZMWIEo0eP5ssvvwTgscceY+rUqZxzzjl079692Wvdd999/PznP+e0007D6/U27L/lllvo3bs3o0aNYvTo0bz22msNx6677jp69erFsGHDQvQbODKi2twib8ef8ePH65IlS1qdb+O+Mi743wU8c+1YLh7V/B+AMSZ469evZ+jQoeEuxjHtzjvvZMyYMdx8881H5XqB/k1EZKmqjg+U3j4yc6AGYaOYjDFHy7hx40hMTOSJJ54Id1GaZQGCA30Q1sRkjDlali5dGu4iHJL1QWCd1MYYE4gFCKyT2hhjArEAgdUgjDEmEAsQWCe1McYEYgECZ7nRmMgIYqMsQBhjTD0LENhyo8YYR1JSUriLcEyxRnfqA4T9KowJmY8fgH2r2/ac3UbChY+17TmPER6P55iYm8lqEDh9EDaCyZj25/777+dPf/pTw/bMmTN55JFHmDx5MmPHjmXkyJG89957QZ2rvLy82Xxz5sxpmErjhhtuACA3N5fLL7+c0aNHM3r0aBYuXMiOHTsYMWJEQ77f//73zJw5E4CzzjqLBx98kDPPPJMnn3ySDz74gIkTJzJmzBjOPfdccnNzG8oxY8YMRo4cyahRo3jrrbd44YUXuOeeexrO+/zzz3Pvvfce9u+tgaq2m69x48bp4bj2+W/1ij99c1h5jTGBrVu3LtxF0GXLlumkSZMatocOHao7d+7U0tJSVVXNz8/X/v37q8/nU1XVxMTEZs9VV1cXMN+aNWt00KBBmp+fr6qqhYWFqqp69dVX6x//+EdVVfV4PFpSUqLbt2/X4cOHN5zz8ccf14cfflhVVc8880z9yU9+0nCsqKiooVzPP/+83nvvvaqqet999+ndd9/dKF15ebn269dPa2trVVX1lFNO0VWrVh10D4H+TYAl2swz1T4243RSp8ZHh7sYxpg2NmbMGPLy8tizZw/5+fmkp6fTvXt37rnnHhYsWEBERAS7d+8mNzeXbt26tXguVeXBBx88KN8XX3zBlVdeSefOnYED6z188cUXDWs8REZGkpqaeshFiOonDgTIycnhmmuuYe/evdTW1jasX9HcuhXnnHMOH374IUOHDqWuro6RI0e28rd1MAsQOH0QPdPiwl0MY0wIXHnllcydO5d9+/Yxffp0Xn31VfLz81m6dCnR0dH06dPnoHUeAmkunzaz3kMgUVFR+Hy+hu2W1pe46667uPfee7nkkkv46quvGpqimrveLbfcwm9+8xuGDBnSZqvTWR8Ebie1LRZkTLs0ffp03njjDebOncuVV15JaWkpXbp0ITo6mi+//JKdO3cGdZ7m8k2ePJk333yTwsJC4MB6D5MnT+bZZ58FwOv1sn//frp27UpeXh6FhYXU1NTw4Ycftni9+vUlXn755Yb9za1bMXHiRLKzs3nttdf44Q9/GOyvp0UWILDlRo1pz4YPH05ZWRk9e/ake/fuXHfddSxZsoTx48fz6quvMmTIkKDO01y+4cOH84tf/IIzzzyT0aNHN3QOP/nkk3z55ZeMHDmScePGsXbtWqKjo/nVr37FxIkTmTp1aovXnjlzJldddRVnnHFGQ/MVNL9uBcDVV1/NaaedFtRyqcGw9SCAn76xnEmDMrlibFYISmVMx2TrQRx9U6dO5Z577mHy5MkBj7d2PYiQ1iBEZIqIbBSRLSLyQIDjPxORFe7XGhHxikhGMHnb0v9OH2PBwRhz3CopKWHQoEHEx8c3GxwOR8jaVUQkEngGOA/IARaLyPuquq4+jao+Djzupp8G3KOqRcHkNcaYUFi9enXDuwz1YmNj+f7778NUokNLS0tj06ZNbX7eUDa8TwC2qOo2ABF5A7gUaO4h/0Pg9cPMa4w5BrVmhM+xYuTIkaxYsSLcxWhzh9OdEMompp5Att92jrvvICKSAEwB3jqMvLeJyBIRWZKfn3/EhTbGtI24uDgKCwsP68Fk2paqUlhYSFxc64bzh7IGEehjQ3N/KdOAb1S1qLV5VfU54DlwOqlbW0hjTGhkZWWRk5ODfXA7NsTFxZGV1bq+1lAGiBygl992FrCnmbTTOdC81Nq8xphjUHR0dMPbv+b4FMompsXAQBHpKyIxOEHg/aaJRCQVOBN4r7V5jTHGhE7IahCq6hGRO4FPgEjgRVVdKyK3u8dnuUkvBz5V1YpD5Q1VWY0xxhzMXpQzxpgOrKUX5dpVgBCRfCC4iVUO1hkoaMPiHA864j1Dx7zvjnjP0DHvu7X3fIKqZgY60K4CxJEQkSXNRdH2qiPeM3TM++6I9wwd877b8p5tsj5jjDEBWYAwxhgTkAWIA54LdwHCoCPeM3TM++6I9wwd877b7J6tD8IYY0xAVoMwxhgTkAUIY4wxAXX4AHE0FyYKJxHpJSJfish6EVkrIne7+zNE5DMR2ex+b5u1Co8hIhIpIstF5EN3uyPcc5qIzBWRDe6/+Snt/b5F5B73b3uNiLwuInHt8Z5F5EURyRORNX77mr1PEfm5+3zbKCIXtOZaHTpA+C1MdCEwDPihiAwLb6lCxgP8p6oOBU4G7nDv9QHgc1UdCHzubrc3dwPr/bY7wj0/CcxT1SHAaJz7b7f3LSI9gf8AxqvqCJwpeqbTPu95Ns7yCP4C3qf7f3w6MNzN8yf3uReUDh0g8FuYSFVrgfqFidodVd2rqsvcn8twHhg9ce73ZTfZy8BlYSlgiIhIFnAx8Be/3e39nlOAScALAKpaq6oltPP7xplbLl5EooAEnBmg2909q+oCoKjJ7ubu81LgDVWtUdXtwBac515QOnqACHphovZERPoAY4Dvga6quhecIAJ0CWPRQuF/gfsAn9++9n7P/YB84CW3ae0vIpJIO75vVd0N/B7YBewFSlX1U9rxPTfR3H0e0TOuoweI1ixq1C6ISBLOyn0/VdX94S5PKInIVCBPVZeGuyxHWRQwFnhWVccAFbSPppVmuW3ulwJ9gR5AoohcH95SHROO6BnX0QNEh1qYSESicYLDq6r6trs7V0S6u8e7A3nhKl8InAZcIiI7cJoPzxGRV2jf9wzO33WOqn7vbs/FCRjt+b7PBbarar6q1gFvA6fSvu/ZX3P3eUTPuI4eIDrMwkTirBz/ArBeVf/gd+h94Eb35xtpvHDTcU1Vf66qWaraB+ff9gtVvZ52fM8AqroPyBaRwe6uycA62vd97wJOFpEE9299Mk4/W3u+Z3/N3ef7wHQRiRWRvsBAYFHQZ1XVDv0FXARsArYCvwh3eUJ4n6fjVC1XASvcr4uATjijHja73zPCXdYQ3f9ZwIfuz+3+noETgSXuv/e7QHp7v2/gEWADsAb4KxDbHu8ZZ3nmvUAdTg3h5pbuE/iF+3zbCFzYmmvZVBvGGGMC6uhNTMYYY5phAcIYY0xAFiCMMcYEZAHCGGNMQBYgjDHGBGQBwpgwEpGz6meZNeZYYwHCGGNMQBYgjAmCiFwvIotEZIWI/NldY6JcRJ4QkWUi8rmIZLppTxSR70RklYi8Uz83v4gMEJH5IrLSzdPfPX2S39oNr7pvAiMij4nIOvc8vw/TrZsOzAKEMYcgIkOBa4DTVPVEwAtcByQCy1R1LPA18LCbZQ5wv6qOAlb77X8VeEZVR+PME7TX3T8G+CnOmiT9gNNEJAO4HBjunufXobxHYwKxAGHMoU0GxgGLRWSFu90PZwrxv7lpXgFOF5FUIE1Vv3b3vwxMEpFkoKeqvgOgqtWqWummWaSqOarqw5kCpQ+wH6gG/iIiVwD1aY05aixAGHNoArysqie6X4NVdWaAdC3NWxNo2uV6NX4/e4EoVfXgLOzyFs7iL/NaV2RjjpwFCGMO7XPgShHpAg3r/56A8//nSjfNtcC/VLUUKBaRM9z9NwBfq7P2Ro6IXOaeI1ZEEpq7oLtuR6qqfoTT/HRim9+VMYcQFe4CGHOsU9V1IvIQ8KmIRODMonkHzkI8w0VkKVCK008BznTLs9wAsA2Y4e6/AfiziPy3e46rWrhsMvCeiMTh1D7uaePbMuaQbDZXYw6TiJSralK4y2FMqFgTkzHGmICsBmGMMSYgq0EYY4wJyAKEMcaYgCxAGGOMCcgChDHGmIAsQBhjjAno/wN4f94TW/rZFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.title(string + \" graph\")\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_' + string])\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_' + string])\n",
    "    plt.show()\n",
    "    \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11137\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.1969 - accuracy: 0.9513\n",
      "(11137, 3)\n",
      "सीएमटीडीयू [0.12486002, 0.87462986, 0.00051017315] [1, 0, 0]\n",
      "सीएमटीडीयू [0.12486002, 0.87462986, 0.00051017315] [1, 0, 0]\n",
      "बेग [0.011456484, 0.9833702, 0.005173355] [0, 0, 1]\n",
      "जमी [0.05398917, 0.9325103, 0.013500498] [1, 0, 0]\n",
      "जमी [0.05398917, 0.9325103, 0.013500498] [1, 0, 0]\n",
      "चाप [0.24732955, 0.19643545, 0.5562351] [1, 0, 0]\n",
      "जमी [0.05398917, 0.9325103, 0.013500498] [1, 0, 0]\n",
      "बेअसर [0.0035061077, 0.9918433, 0.0046506245] [0, 0, 1]\n",
      "जमना [0.9259993, 0.045147907, 0.028852858] [0, 0, 1]\n",
      "जमना [0.9259993, 0.045147907, 0.028852858] [0, 0, 1]\n",
      "नजारा [0.0061697876, 0.12732537, 0.8665048] [0, 1, 0]\n",
      "कौतुहल [0.96617824, 0.027280314, 0.0065414174] [0, 1, 0]\n",
      "छटा [0.0789393, 0.88467574, 0.036385026] [1, 0, 0]\n",
      "खुशनसीबी [0.1558914, 0.83586514, 0.008243416] [1, 0, 0]\n",
      "जमी [0.05398917, 0.9325103, 0.013500498] [1, 0, 0]\n",
      "जमी [0.05398917, 0.9325103, 0.013500498] [1, 0, 0]\n",
      "करजाट [0.24295609, 0.05120103, 0.70584285] [0, 1, 0]\n",
      "सियासी [0.4992399, 0.4000712, 0.100688934] [0, 0, 1]\n",
      "सियासी [0.4992399, 0.4000712, 0.100688934] [0, 0, 1]\n",
      "आँक [0.15688054, 0.6808561, 0.1622634] [1, 0, 0]\n",
      "आवाम [0.007973645, 0.9799963, 0.012030009] [1, 0, 0]\n",
      "07 [9.718819e-13, 2.3315914e-13, 1.0] [0, 1, 0]\n",
      "सात [0.026894443, 0.6687287, 0.3043768] [0, 0, 1]\n",
      "अर्चना [0.45527962, 0.5158315, 0.028888855] [1, 0, 0]\n",
      "खतामी [0.9986644, 0.000736469, 0.0005992031] [0, 1, 0]\n",
      "खतामी [0.9986644, 0.000736469, 0.0005992028] [0, 1, 0]\n",
      "हिमलिंग [0.7867783, 0.14037234, 0.07284937] [0, 1, 0]\n",
      "हिमलिंग [0.7867783, 0.14037234, 0.07284937] [0, 1, 0]\n",
      "हिमलिंग [0.78677845, 0.14037226, 0.072849296] [0, 1, 0]\n",
      "पिघलने [0.018420966, 0.4038103, 0.57776874] [1, 0, 0]\n",
      "हिमलिंग [0.7867783, 0.14037234, 0.07284937] [0, 1, 0]\n",
      "संरक्षा [0.0012870964, 0.9985753, 0.00013763] [1, 0, 0]\n",
      "1847 [0.15763593, 0.504263, 0.33810115] [0, 0, 1]\n",
      "रासमणि [0.0002621406, 0.9997236, 1.4196196e-05] [1, 0, 0]\n",
      "काली [0.13644797, 0.8188508, 0.044701274] [1, 0, 0]\n",
      "1855 [0.018472925, 0.97074866, 0.010778357] [0, 0, 1]\n",
      "काली [0.13644797, 0.8188508, 0.044701274] [1, 0, 0]\n",
      "काली [0.13644797, 0.8188508, 0.044701274] [1, 0, 0]\n",
      "काली [0.13644797, 0.8188508, 0.044701274] [1, 0, 0]\n",
      "काली [0.13644797, 0.8188508, 0.044701274] [1, 0, 0]\n",
      "काली [0.13644797, 0.8188508, 0.044701274] [1, 0, 0]\n",
      "मंजिलों [0.0020420437, 0.99610484, 0.0018531125] [1, 0, 0]\n",
      "काली [0.13644797, 0.8188508, 0.044701274] [1, 0, 0]\n",
      "आराधना [0.01064415, 0.97629184, 0.013064009] [1, 0, 0]\n",
      "काली [0.13644797, 0.8188508, 0.044701274] [1, 0, 0]\n",
      "प्रसिद्ध [0.8419575, 0.000647285, 0.15739523] [0, 0, 1]\n",
      "काली [0.13644797, 0.8188508, 0.044701274] [1, 0, 0]\n",
      "प्राचीन [0.93061846, 0.057976928, 0.011404627] [0, 0, 1]\n",
      "1030 [0.04111152, 0.5598794, 0.3990091] [0, 0, 1]\n",
      "ऑर्गिनाइजेशन [0.001288069, 0.99642676, 0.0022851685] [1, 0, 0]\n",
      "खेरा [0.9980052, 0.0010524095, 0.00094234734] [0, 0, 1]\n",
      "रोधी [0.26758993, 0.49771288, 0.23469718] [0, 0, 1]\n",
      "भाल [0.005061862, 0.9883519, 0.0065862476] [1, 0, 0]\n",
      "हजारीबाग [0.60389805, 0.36352512, 0.03257671] [0, 1, 0]\n",
      "तलाबानी [0.5620975, 0.3834612, 0.054441325] [0, 1, 0]\n",
      "तलाबानी [0.5620975, 0.3834612, 0.054441325] [0, 1, 0]\n",
      "तलाबानी [0.5620975, 0.3834612, 0.054441325] [0, 1, 0]\n",
      "तलाबानी [0.5620975, 0.3834612, 0.054441325] [0, 1, 0]\n",
      "तलाबानी [0.5620975, 0.3834612, 0.054441325] [0, 1, 0]\n",
      "नामक [0.019714125, 0.5195442, 0.46074176] [0, 0, 1]\n",
      "तलाबानी [0.56209725, 0.38346136, 0.054441325] [0, 1, 0]\n",
      "लकवा [0.5444559, 0.43278906, 0.022755047] [0, 1, 0]\n",
      "बिश्वास [0.079689704, 0.8047997, 0.115510605] [0, 0, 1]\n",
      "लकवा [0.5444559, 0.43278906, 0.022755047] [0, 1, 0]\n",
      "बिश्वास [0.079689704, 0.8047997, 0.115510605] [0, 0, 1]\n",
      "नकारते [0.01025232, 0.17380723, 0.81594044] [0, 1, 0]\n",
      "जीओसी [0.65114534, 0.31816566, 0.030688992] [0, 1, 0]\n",
      "छींटाकशी [0.2797837, 0.59201396, 0.12820235] [1, 0, 0]\n",
      "नाक़ाम [0.16041866, 0.4296324, 0.40994886] [0, 0, 1]\n",
      "मूँगफली [0.32095516, 0.66745156, 0.011593289] [1, 0, 0]\n",
      "सोयाबीन [0.12965663, 0.85511297, 0.015230325] [1, 0, 0]\n",
      "मूँगफली [0.32095516, 0.66745156, 0.011593289] [1, 0, 0]\n",
      "445 [0.022008417, 0.97192085, 0.0060707205] [0, 0, 1]\n",
      "सोयाबीन [0.12965663, 0.85511297, 0.015230325] [1, 0, 0]\n",
      "मूँगफली [0.32095516, 0.66745156, 0.011593289] [1, 0, 0]\n",
      "सोयाबीन [0.12965663, 0.85511297, 0.015230325] [1, 0, 0]\n",
      "बैजोरिया [0.0011000751, 0.99731535, 0.0015845281] [0, 0, 1]\n",
      "आँकड़ें [0.9519582, 0.038053893, 0.009987907] [0, 1, 0]\n",
      "फिसलन [0.146389, 0.60272324, 0.2508878] [1, 0, 0]\n",
      "खिलाड़ी [0.53075093, 0.38269714, 0.08655186] [0, 1, 0]\n",
      "जुमलेबाजी [0.068521924, 0.9084213, 0.023056798] [1, 0, 0]\n",
      "द्रविड़ [0.035689607, 0.90618145, 0.05812897] [0, 0, 1]\n",
      "डिपेंडेबल [0.078830436, 0.8828283, 0.0383413] [0, 0, 1]\n",
      "रामसिंहासन [0.030585729, 0.95176, 0.017654313] [0, 0, 1]\n",
      "बीएसएस [0.03277227, 0.9524225, 0.01480523] [1, 0, 0]\n",
      "420 [0.0034544202, 0.0016264872, 0.9949191] [0, 1, 0]\n",
      "467 [0.0, 0.0, 1.0] [0, 1, 0]\n",
      "468 [0.015701206, 0.08630478, 0.89799404] [0, 1, 0]\n",
      "470 [0.9999515, 3.9905162e-06, 4.4623583e-05] [0, 1, 0]\n",
      "सम्मत [0.4607573, 0.19302097, 0.34622177] [0, 0, 1]\n",
      "दोहराने [0.008929461, 0.6222332, 0.3688373] [0, 0, 1]\n",
      "बनानी [0.28519538, 0.603973, 0.110831626] [1, 0, 0]\n",
      "खटास [0.28083822, 0.6508244, 0.06833738] [1, 0, 0]\n",
      "ताल [0.78784794, 0.19898684, 0.013165174] [0, 1, 0]\n",
      "विख्यात [0.62284136, 0.25258183, 0.124576874] [0, 0, 1]\n",
      "प्राचीन [0.93061846, 0.057976928, 0.011404627] [0, 0, 1]\n",
      "उत्तम [0.007528916, 0.90704405, 0.08542698] [0, 0, 1]\n",
      "गंगोतरी [0.8772465, 0.07614817, 0.046605308] [0, 1, 0]\n",
      "प्रसिद्ध [0.8419575, 0.000647285, 0.15739523] [0, 0, 1]\n",
      "धूनी [0.35341388, 0.5854591, 0.061127078] [1, 0, 0]\n",
      "किंवदंती [0.010441916, 0.9644649, 0.025093205] [1, 0, 0]\n",
      "पूजित [0.9829972, 0.011188445, 0.0058143423] [0, 0, 1]\n",
      "पड़वा [0.0075008916, 0.97469586, 0.01780323] [1, 0, 0]\n",
      "ऋतु [5.8736155e-06, 0.99981016, 0.00018407182] [1, 0, 0]\n",
      "जलता [0.686139, 0.3034403, 0.010420656] [0, 1, 0]\n",
      "दंडी [0.76332164, 0.21654667, 0.020131612] [0, 1, 0]\n",
      "ऊखीमठ [0.78278995, 0.15562055, 0.061589442] [0, 1, 0]\n",
      "ब्रह्मलीन [0.092047915, 0.80523443, 0.102717675] [0, 0, 1]\n",
      "विडंबना [0.0047162795, 0.96754295, 0.0277408] [1, 0, 0]\n",
      "क्रिया [0.28172278, 0.7005503, 0.01772694] [1, 0, 0]\n",
      "1120 [0.012156333, 0.81401014, 0.17383356] [0, 0, 1]\n",
      "जगाधरी [0.5242555, 0.43744346, 0.038301043] [0, 1, 0]\n",
      "चिंताजनक [0.097845025, 0.5448129, 0.35734206] [0, 0, 1]\n",
      "खगड़िया [0.7138504, 0.046974506, 0.23917516] [0, 1, 0]\n",
      "समस्तीपुर [0.47917378, 0.47287446, 0.047951683] [0, 1, 0]\n",
      "ब्रह्मपुत्र [0.04779513, 0.8918311, 0.060373843] [1, 0, 0]\n",
      "नदियों [0.106943145, 0.8838721, 0.009184695] [1, 0, 0]\n",
      "ब्रह्मपुत्र [0.04779513, 0.8918311, 0.060373843] [1, 0, 0]\n",
      "चिंताजनक [0.097845025, 0.5448129, 0.35734206] [0, 0, 1]\n",
      "पीटा [0.8395154, 0.14688973, 0.013594858] [0, 1, 0]\n",
      "ज्यादतियों [0.270423, 0.66067505, 0.06890199] [1, 0, 0]\n",
      "वाड्रा [0.0088028945, 0.97723, 0.013967022] [0, 0, 1]\n",
      "जैदी [0.9638004, 0.014505908, 0.021693647] [0, 1, 0]\n",
      "२२४ [0.059398506, 0.898235, 0.042366497] [0, 0, 1]\n",
      "संभाले [0.65442014, 0.2587193, 0.08686057] [0, 1, 0]\n",
      "यूनानी [0.065765135, 0.9152603, 0.018974578] [1, 0, 0]\n",
      "तकरार [0.13968197, 0.48821366, 0.37210447] [1, 0, 0]\n",
      "बालासुब्रह्मण्यम् [0.0039680353, 0.10815517, 0.88787687] [0, 1, 0]\n",
      "बदसलूकी [0.3921032, 0.5376728, 0.070223965] [1, 0, 0]\n",
      "टाईप [0.9756732, 0.015719783, 0.008606989] [0, 1, 0]\n",
      "दक्षिणी [0.072115, 0.8645542, 0.06333085] [0, 0, 1]\n",
      "जिरकातन [0.1581866, 0.21373427, 0.6280791] [0, 1, 0]\n",
      "नामक [0.019714125, 0.5195442, 0.46074176] [0, 0, 1]\n",
      "शोंपेन [0.0061619156, 0.99036765, 0.003470442] [1, 0, 0]\n",
      "अंडमानी [0.6219146, 0.2866291, 0.0914563] [0, 1, 0]\n",
      "ट्यूब [0.013695222, 0.96415883, 0.02214601] [1, 0, 0]\n",
      "नलसार [0.07116426, 0.79866934, 0.13016637] [1, 0, 0]\n",
      "सुलेमसराय [9.3379447e-07, 0.99999034, 8.698964e-06] [1, 0, 0]\n",
      "सुधाकांत [0.55041283, 0.41235992, 0.037227258] [0, 1, 0]\n",
      "स्वास्तिका [0.025565065, 0.6111305, 0.3633044] [1, 0, 0]\n",
      "काल्पनिक [0.023572711, 0.9533975, 0.023029814] [0, 0, 1]\n",
      "जयमाला [0.00016322297, 0.9990723, 0.00076445896] [1, 0, 0]\n",
      "जयमाला [0.00016322297, 0.9990723, 0.00076445896] [1, 0, 0]\n",
      "जयमाला [0.00016322297, 0.9990723, 0.00076445896] [1, 0, 0]\n",
      "जयमाला [0.00016322297, 0.9990723, 0.00076445896] [1, 0, 0]\n",
      "श्रद्धा [0.19679062, 0.70600855, 0.09720086] [1, 0, 0]\n",
      "डगमगाने [0.013647027, 0.944025, 0.042327944] [0, 0, 1]\n",
      "केरल [0.012938954, 0.11368318, 0.8733778] [0, 1, 0]\n",
      "मनाही [0.35567582, 0.6080612, 0.03626302] [1, 0, 0]\n",
      "सुखदेव [0.14783941, 0.07520659, 0.77695394] [0, 1, 0]\n",
      "सेनानियों [0.6794293, 0.20804071, 0.112529956] [0, 1, 0]\n",
      "अनसुनी [0.13528879, 0.8131723, 0.05153896] [1, 0, 0]\n",
      "१९३१ [0.0012342348, 0.99257857, 0.0061871638] [0, 0, 1]\n",
      "नामांकित [0.83479404, 0.0680128, 0.09719322] [0, 0, 1]\n",
      "पुरातन [0.005756842, 0.97914016, 0.015103012] [0, 0, 1]\n",
      "उदासीनता [0.15956818, 0.82295084, 0.017480984] [1, 0, 0]\n",
      "मुंगेकर [0.021675168, 0.93021965, 0.048105236] [0, 0, 1]\n",
      "संलग्न [0.005438321, 0.9807793, 0.013782445] [0, 0, 1]\n",
      "०५८ [0.021896318, 0.63876003, 0.33934358] [0, 0, 1]\n",
      "काबिल [0.03171256, 0.64841217, 0.3198753] [0, 0, 1]\n",
      "पाना [0.004882624, 0.96687126, 0.028246114] [0, 0, 1]\n",
      "शीतकाल [0.80077827, 0.18091771, 0.018304003] [0, 1, 0]\n",
      "नारीवेश [0.5685317, 0.1098805, 0.32158774] [0, 1, 0]\n",
      "माणा [0.5889188, 0.3646194, 0.046461746] [0, 1, 0]\n",
      "कन्याओं [0.04162136, 0.9564835, 0.001895204] [1, 0, 0]\n",
      "शीतकाल [0.80077827, 0.18091771, 0.018304003] [0, 1, 0]\n",
      "धुन [0.0051412107, 0.98695624, 0.007902542] [1, 0, 0]\n",
      "मंत्रमुग्ध [0.20167075, 0.777503, 0.02082625] [0, 0, 1]\n",
      "मैखुरी [0.54910076, 0.4421635, 0.0087358365] [0, 1, 0]\n",
      "वेदपाठी [0.9331142, 0.032510526, 0.034375206] [0, 1, 0]\n",
      "माणा [0.5889188, 0.3646194, 0.046461746] [0, 1, 0]\n",
      "दिवसीय [0.17859904, 0.6935775, 0.12782338] [0, 0, 1]\n",
      "गदर [0.1238311, 0.12043772, 0.7557311] [0, 1, 0]\n",
      "औपचारिकताएँ [0.095776185, 0.8779469, 0.026276957] [1, 0, 0]\n",
      "सुपुर्द [0.011283559, 0.95962673, 0.029089678] [0, 0, 1]\n",
      "वेश्यावृत्ति [0.45376307, 0.4596285, 0.08660841] [1, 0, 0]\n",
      "तलाशने [0.013090509, 0.7085526, 0.27835685] [0, 0, 1]\n",
      "तस्कर [0.05068445, 0.10542954, 0.8438861] [0, 1, 0]\n",
      "तस्कर [0.05068445, 0.10542954, 0.8438861] [0, 1, 0]\n",
      "इनको [0.034860075, 0.5136653, 0.45147458] [0, 0, 1]\n",
      "1985 [0.021133246, 0.96426755, 0.014599201] [0, 0, 1]\n",
      "85 [0.00541642, 0.9703344, 0.02424917] [0, 0, 1]\n",
      "तेदेपा [6.0497373e-06, 0.9957496, 0.0042443154] [1, 0, 0]\n",
      "भूमिगत [0.9029775, 0.08622457, 0.010797876] [0, 0, 1]\n",
      "हारी [0.1609877, 0.82782423, 0.0111880135] [1, 0, 0]\n",
      "पॉवर [0.047081202, 0.9462674, 0.0066513144] [1, 0, 0]\n",
      "घराने [0.0022254046, 0.013635097, 0.98413944] [0, 1, 0]\n",
      "उत्पादित [0.706602, 0.23441768, 0.05898029] [0, 0, 1]\n",
      "पॉवर [0.047081202, 0.9462674, 0.0066513144] [1, 0, 0]\n",
      "पॉवर [0.047081202, 0.9462674, 0.0066513144] [1, 0, 0]\n",
      "बंदिशों [0.06190099, 0.93338495, 0.0047140266] [1, 0, 0]\n",
      "पॉवर [0.047081202, 0.9462674, 0.0066513144] [1, 0, 0]\n",
      "दांगी [0.8573252, 0.07220558, 0.07046917] [0, 0, 1]\n",
      "ज्यादतियों [0.27042302, 0.660675, 0.06890204] [1, 0, 0]\n",
      "अपहृत [0.19766888, 0.59387386, 0.2084572] [0, 0, 1]\n",
      "सरदाना [0.082409725, 0.8998643, 0.01772595] [0, 0, 1]\n",
      "जगाधरी [0.5242555, 0.43744346, 0.038301043] [0, 1, 0]\n",
      "पतंग [0.23170559, 0.5064966, 0.26179785] [1, 0, 0]\n",
      "पुलिया [0.86659944, 0.11910508, 0.014295503] [0, 1, 0]\n",
      "संधि [0.43854403, 0.52174103, 0.039714858] [1, 0, 0]\n",
      "मुईवा [0.9996762, 0.00027937748, 4.4497174e-05] [0, 1, 0]\n",
      "संधि [0.43854418, 0.521741, 0.039714873] [1, 0, 0]\n",
      "उमर [0.499858, 0.4650768, 0.035065196] [0, 1, 0]\n",
      "उमर [0.499858, 0.4650768, 0.035065196] [0, 1, 0]\n",
      "उमर [0.499858, 0.4650768, 0.035065196] [0, 1, 0]\n",
      "कलां [0.69992757, 0.24344525, 0.056627184] [0, 1, 0]\n",
      "सिहाग [0.89311206, 0.069700755, 0.03718722] [0, 1, 0]\n",
      "मनियारी [0.9647038, 0.012899453, 0.022396635] [0, 1, 0]\n",
      "मनियारी [0.9647038, 0.012899453, 0.022396635] [0, 1, 0]\n",
      "मनियारी [0.9647038, 0.012899453, 0.022396635] [0, 1, 0]\n",
      "तिर्की [0.06496858, 0.22303323, 0.7119982] [0, 1, 0]\n",
      "मनियारी [0.9647038, 0.012899453, 0.022396635] [0, 1, 0]\n",
      "सिहाग [0.89311206, 0.069700755, 0.03718722] [0, 1, 0]\n",
      "जेब [0.09483302, 0.884966, 0.020200899] [1, 0, 0]\n",
      "निर्मला [0.15738511, 0.7712436, 0.07137137] [1, 0, 0]\n",
      "निर्मला [0.15738511, 0.7712436, 0.07137137] [1, 0, 0]\n",
      "अल्पसंख्या [0.051435493, 0.8564893, 0.092075214] [1, 0, 0]\n",
      "जनगणना [2.520161e-05, 0.9712971, 0.028677717] [1, 0, 0]\n",
      "सिक्ख [0.77243704, 0.13658607, 0.090977006] [0, 1, 0]\n",
      "बहुसंख्यक [0.22054973, 0.4589834, 0.32046697] [0, 0, 1]\n",
      "दूत [0.4671497, 0.45429057, 0.078559786] [0, 1, 0]\n",
      "किक [0.007295189, 0.9838133, 0.008891509] [1, 0, 0]\n",
      "करतब [0.8076921, 0.10688093, 0.085427016] [0, 1, 0]\n",
      "एनएफयूएजे [0.0029057192, 0.99707043, 2.3749602e-05] [1, 0, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "दूत [0.4671497, 0.45429057, 0.078559786] [0, 1, 0]\n",
      "माँसपेशियों [0.342357, 0.6530601, 0.004582891] [1, 0, 0]\n",
      "सुनाकर [0.020382414, 0.7576278, 0.22198977] [0, 0, 1]\n",
      "करतब [0.8076921, 0.10688093, 0.085427016] [0, 1, 0]\n",
      "प्रवाहित [0.0066185566, 0.5996008, 0.39378062] [0, 0, 1]\n",
      "टिहरी [0.95803094, 0.03496549, 0.007003601] [0, 1, 0]\n",
      "गलने [0.053018324, 0.9155749, 0.031406827] [0, 0, 1]\n",
      "कार्ययोजना [0.2637594, 0.6696373, 0.06660331] [1, 0, 0]\n",
      "नदियों [0.106943145, 0.8838721, 0.009184695] [1, 0, 0]\n",
      "07 [9.718819e-13, 2.3315914e-13, 1.0] [0, 1, 0]\n",
      "06 [1.1607846e-10, 1.1554963e-10, 1.0] [0, 1, 0]\n",
      "कोर [0.005360091, 0.024655543, 0.96998435] [0, 1, 0]\n",
      "खेप [0.0023551711, 0.994169, 0.003475959] [1, 0, 0]\n",
      "खेप [0.0023551711, 0.994169, 0.003475959] [1, 0, 0]\n",
      "श्रॉफ [0.0074886545, 0.9899553, 0.002555993] [0, 0, 1]\n",
      "खेप [0.0023551711, 0.994169, 0.003475959] [1, 0, 0]\n",
      "दर्द [0.039203633, 0.4172685, 0.54352784] [0, 1, 0]\n",
      "दर्द [0.039203633, 0.4172685, 0.54352784] [0, 1, 0]\n",
      "क़बूल [0.0036440804, 0.9923982, 0.0039576567] [0, 0, 1]\n",
      "परतों [0.03684813, 0.9589272, 0.004224633] [1, 0, 0]\n",
      "बरछियों [0.015085057, 0.97296244, 0.01195254] [1, 0, 0]\n",
      "नजारा [0.0061697876, 0.12732537, 0.8665048] [0, 1, 0]\n",
      "वशिष्ठ [0.6437551, 0.13534202, 0.22090288] [0, 1, 0]\n",
      "आमद [0.10034492, 0.8514734, 0.048181742] [1, 0, 0]\n",
      "दुर्गापूजा [0.15702887, 0.7717306, 0.0712405] [1, 0, 0]\n",
      "आकाओं [0.5483227, 0.382081, 0.06959625] [0, 1, 0]\n",
      "बाछें [0.22230518, 0.5407843, 0.23691057] [1, 0, 0]\n",
      "आकाओं [0.5483227, 0.382081, 0.06959625] [0, 1, 0]\n",
      "खटखटाओ [0.209269, 0.67226285, 0.11846812] [0, 0, 1]\n",
      "हताशा [0.021018442, 0.9758729, 0.0031086698] [1, 0, 0]\n",
      "तैयबा [0.48863146, 0.1671452, 0.34422338] [0, 1, 0]\n",
      "तैयबा [0.48863146, 0.1671452, 0.34422338] [0, 1, 0]\n",
      "हासिम [0.45451704, 0.22185622, 0.32362676] [0, 1, 0]\n",
      "बाड़ [0.25414357, 0.6520912, 0.093765326] [1, 0, 0]\n",
      "बैरीकेडिंग [0.31281406, 0.66400623, 0.023179697] [1, 0, 0]\n",
      "लाँघ [1.7850069e-05, 0.9998503, 0.00013187919] [0, 0, 1]\n",
      "बैरीकेडिंग [0.31281406, 0.66400623, 0.023179697] [1, 0, 0]\n",
      "निजता [0.12661825, 0.76580346, 0.10757828] [1, 0, 0]\n",
      "रासायनिक [0.4495388, 0.48422453, 0.066236645] [0, 0, 1]\n",
      "भौतिक [0.89443594, 0.09330815, 0.012255893] [0, 0, 1]\n",
      "रंजना [0.024168285, 0.9693896, 0.006442192] [1, 0, 0]\n",
      "रंजना [0.024168285, 0.9693896, 0.006442192] [1, 0, 0]\n",
      "रंजना [0.024168285, 0.9693896, 0.006442192] [1, 0, 0]\n",
      "केरल [0.012938954, 0.11368318, 0.8733778] [0, 1, 0]\n",
      "केरल [0.01293896, 0.11368318, 0.8733778] [0, 1, 0]\n",
      "सोचिए [0.007951902, 0.92441964, 0.06762845] [0, 0, 1]\n",
      "प्रतियोगी [0.50856715, 0.32915756, 0.16227522] [0, 1, 0]\n",
      "अप्लाइंसेज़ [0.43535933, 0.4292318, 0.13540883] [0, 1, 0]\n",
      "नाक़ामयाब [0.23083636, 0.61912626, 0.15003744] [0, 0, 1]\n",
      "कड़वाहट [0.33157247, 0.6306896, 0.03773796] [1, 0, 0]\n",
      "शकुनी [0.7061658, 0.1901266, 0.10370756] [0, 1, 0]\n",
      "बचके [0.004504703, 0.9463503, 0.049145073] [0, 0, 1]\n",
      "रहो [0.06674241, 0.58826876, 0.34498882] [0, 0, 1]\n",
      "चुनें [0.038420673, 0.631271, 0.33030832] [0, 0, 1]\n",
      "नाक़ामयाब [0.23083636, 0.61912626, 0.15003744] [0, 0, 1]\n",
      "खास [0.15730469, 0.49277115, 0.3499242] [0, 0, 1]\n",
      "बरता [0.74541366, 0.14478733, 0.10979899] [0, 1, 0]\n",
      "पीएलआर [0.2515094, 0.72858405, 0.01990659] [1, 0, 0]\n",
      "१०२५ [0.010855135, 0.8654708, 0.12367404] [0, 0, 1]\n",
      "बेलगाम [0.047962114, 0.84182996, 0.11020789] [0, 0, 1]\n",
      "मार्जिन [0.006649279, 0.037479438, 0.9558713] [0, 1, 0]\n",
      "दृष्टांत [0.6461611, 0.33927488, 0.014564078] [0, 1, 0]\n",
      "ढूँढ़े [0.010182072, 0.9574728, 0.032345083] [0, 0, 1]\n",
      "फौजों [0.12560722, 0.8564904, 0.017902413] [1, 0, 0]\n",
      "टोकना [0.33222985, 0.6267488, 0.041021377] [0, 0, 1]\n",
      "कृष्णन् [4.3533175e-05, 0.9985202, 0.0014361977] [0, 0, 1]\n",
      "सम्मिलित [0.8372422, 0.00366961, 0.15908821] [0, 0, 1]\n",
      "आंखन [0.3874574, 0.39160302, 0.22093959] [1, 0, 0]\n",
      "जगाने [0.013006969, 0.8611508, 0.12584223] [0, 0, 1]\n",
      "साबत [0.9237625, 0.039099775, 0.037137646] [0, 0, 1]\n",
      "फूँक [0.03172784, 0.68968374, 0.27858847] [0, 0, 1]\n",
      "गिरि [0.9407961, 0.050114706, 0.009089205] [0, 1, 0]\n",
      "साधु [0.9878036, 0.0060261893, 0.0061702877] [0, 1, 0]\n",
      "गिरि [0.9407961, 0.050114706, 0.009089205] [0, 1, 0]\n",
      "अर्चना [0.45528007, 0.515831, 0.028888842] [1, 0, 0]\n",
      "गिरि [0.9407961, 0.050114706, 0.009089205] [0, 1, 0]\n",
      "अर्चना [0.45527962, 0.5158315, 0.028888855] [1, 0, 0]\n",
      "साधु [0.9878036, 0.0060261893, 0.0061702877] [0, 1, 0]\n",
      "उत्कृष्टता [0.24182214, 0.725433, 0.032744862] [1, 0, 0]\n",
      "रोशे [9.16454e-05, 0.99912757, 0.0007808193] [1, 0, 0]\n",
      "बायो [0.00014790718, 0.99891937, 0.0009327104] [0, 0, 1]\n",
      "रेलों [0.32663056, 0.6395123, 0.033857156] [1, 0, 0]\n",
      "घास [0.007636233, 0.9847841, 0.007579611] [1, 0, 0]\n",
      "बनायीं [0.19405212, 0.042830415, 0.76311743] [0, 1, 0]\n",
      "विद्या [0.12854871, 0.8534517, 0.017999481] [1, 0, 0]\n",
      "तार [0.959879, 0.03491585, 0.0052051744] [0, 1, 0]\n",
      "ब्राह्मण [0.0075818216, 0.14758757, 0.84483063] [0, 1, 0]\n",
      "गुनियों [0.7838532, 0.19633578, 0.019811051] [0, 1, 0]\n",
      "डायरेक्टरी [0.33161557, 0.6261105, 0.042273927] [1, 0, 0]\n",
      "काल [0.647961, 0.32243496, 0.029604094] [0, 1, 0]\n",
      "मोहरों [0.029516293, 0.95888776, 0.011596026] [1, 0, 0]\n",
      "सुलतान [0.8134942, 0.15569846, 0.030807342] [0, 1, 0]\n",
      "खरीदकर [0.6115148, 0.2889379, 0.09954731] [0, 0, 1]\n",
      "निजाम [0.011376373, 0.21265997, 0.77596366] [0, 1, 0]\n",
      "निजाम [0.011376373, 0.21265997, 0.77596366] [0, 1, 0]\n",
      "फौजिया [0.0013062367, 0.9901365, 0.008557239] [1, 0, 0]\n",
      "मोहरों [0.029516293, 0.95888776, 0.011596026] [1, 0, 0]\n",
      "इनको [0.034860075, 0.5136653, 0.45147458] [0, 0, 1]\n",
      "नीलाम [0.006746797, 0.98775303, 0.005500217] [0, 0, 1]\n",
      "मोहरों [0.029516293, 0.95888776, 0.011596026] [1, 0, 0]\n",
      "सेमी [0.07967665, 0.2254341, 0.6948892] [0, 1, 0]\n",
      "काल [0.647961, 0.32243496, 0.029604094] [0, 1, 0]\n",
      "मोहरों [0.029516293, 0.95888776, 0.011596026] [1, 0, 0]\n",
      "काल [0.647961, 0.32243496, 0.029604094] [0, 1, 0]\n",
      "सेमी [0.07967665, 0.2254341, 0.6948892] [0, 1, 0]\n",
      "फौजिया [0.0013062367, 0.9901365, 0.008557239] [1, 0, 0]\n",
      "1855 [0.018472925, 0.97074866, 0.010778357] [0, 0, 1]\n",
      "दुर्गादेवी [0.0014926854, 0.97978777, 0.018719498] [1, 0, 0]\n",
      "मिठाइयों [0.047316115, 0.9367352, 0.015948722] [1, 0, 0]\n",
      "महाशक्ति [0.27019367, 0.61049354, 0.119312756] [1, 0, 0]\n",
      "अपमानित [0.057239626, 0.919358, 0.023402352] [0, 0, 1]\n",
      "भस्म [0.010111318, 0.95703423, 0.03285437] [0, 0, 1]\n",
      "अर्चना [0.45527962, 0.5158315, 0.028888855] [1, 0, 0]\n",
      "चित्रकला [0.21004914, 0.67835087, 0.111600034] [1, 0, 0]\n",
      "नवरात्रि [0.16645862, 0.3937414, 0.4397999] [1, 0, 0]\n",
      "अर्चना [0.45528007, 0.515831, 0.028888842] [1, 0, 0]\n",
      "830 [0.0036424384, 0.97597265, 0.020384973] [0, 0, 1]\n",
      "रहता [0.5815751, 0.4125848, 0.0058400496] [0, 1, 0]\n",
      "श्रद्धा [0.19679062, 0.70600855, 0.09720086] [1, 0, 0]\n",
      "माला [0.00036774456, 0.998543, 0.0010892473] [1, 0, 0]\n",
      "प्रथा [0.03197518, 0.89367175, 0.07435307] [1, 0, 0]\n",
      "बलि [0.057993736, 0.89690655, 0.045099776] [1, 0, 0]\n",
      "बलि [0.057993736, 0.89690655, 0.045099776] [1, 0, 0]\n",
      "बलि [0.057993736, 0.89690655, 0.045099776] [1, 0, 0]\n",
      "मनोकामना [0.07008329, 0.9198961, 0.010020684] [1, 0, 0]\n",
      "पूर्ण [0.0012850764, 0.9958715, 0.0028434335] [0, 0, 1]\n",
      "गुज़ारिश [0.061909534, 0.93176174, 0.0063286684] [1, 0, 0]\n",
      "फर्म [0.029903397, 0.9559501, 0.014146551] [1, 0, 0]\n",
      "मर्सर [0.071528286, 0.92209584, 0.0063759815] [1, 0, 0]\n",
      "फर्म [0.029903397, 0.9559501, 0.014146551] [1, 0, 0]\n",
      "मर्सर [0.071528286, 0.92209584, 0.0063759815] [1, 0, 0]\n",
      "मर्सर [0.071528286, 0.92209584, 0.0063759815] [1, 0, 0]\n",
      "पुनर्गठित [0.06857296, 0.78770256, 0.14372446] [0, 0, 1]\n",
      "एसजीजेसी [0.99960405, 0.00037246326, 2.3522864e-05] [0, 1, 0]\n",
      "पट्टी [0.9943403, 0.0053664627, 0.00029321402] [0, 0, 1]\n",
      "बडूंगर [0.008067233, 0.9705796, 0.0213532] [0, 0, 1]\n",
      "तलवंडी [0.17017682, 0.69868815, 0.13113508] [0, 0, 1]\n",
      "पट्टी [0.9943403, 0.0053664707, 0.00029321483] [0, 0, 1]\n",
      "काबिज [0.015365097, 0.71188223, 0.2727526] [0, 0, 1]\n",
      "अजनाला [0.01925765, 0.9266693, 0.05407311] [0, 0, 1]\n",
      "पट्टी [0.9943403, 0.0053664627, 0.00029321402] [0, 0, 1]\n",
      "साइंसेस [9.479827e-08, 0.9999999, 9.576797e-09] [1, 0, 0]\n",
      "मैनन [0.086438246, 0.8848807, 0.028680965] [0, 0, 1]\n",
      "खोखले [0.022355594, 0.34856853, 0.62907594] [0, 1, 0]\n",
      "ग्रेटर [0.0032181004, 0.99326515, 0.0035167704] [0, 0, 1]\n",
      "दंपत्ति [0.6720378, 0.20884538, 0.11911688] [0, 1, 0]\n",
      "ग्रेटर [0.0032181004, 0.99326515, 0.0035167704] [0, 0, 1]\n",
      "मालकिन [0.058665194, 0.6249431, 0.31639168] [1, 0, 0]\n",
      "रोमी [0.29752854, 0.63236374, 0.07010778] [1, 0, 0]\n",
      "अवाक [0.028906154, 0.95461136, 0.01648252] [0, 0, 1]\n",
      "बर्द्धन [0.0011343283, 0.40677482, 0.59209085] [0, 1, 0]\n",
      "हिन्दुओं [0.029169075, 0.9641556, 0.0066752564] [0, 0, 1]\n",
      "उड़ाते [0.00014086271, 0.9835933, 0.016265903] [0, 0, 1]\n",
      "सीखते [0.89553005, 0.09042687, 0.014043142] [0, 1, 0]\n",
      "उड़ाई [0.00021101708, 0.99922216, 0.0005667491] [1, 0, 0]\n",
      "बटोरने [0.09120754, 0.6242403, 0.2845521] [0, 0, 1]\n",
      "उगलने [0.049127102, 0.5256254, 0.42524746] [0, 0, 1]\n",
      "फिसड्डी [0.6663695, 0.2832204, 0.05041002] [0, 0, 1]\n",
      "बनानी [0.28519538, 0.603973, 0.110831626] [1, 0, 0]\n",
      "संतोषजनक [0.00064382574, 0.9882361, 0.011119989] [0, 0, 1]\n",
      "बनानी [0.28519538, 0.603973, 0.110831626] [1, 0, 0]\n",
      "संतोषजनक [0.00064382574, 0.9882361, 0.011119989] [0, 0, 1]\n",
      "केरल [0.012938954, 0.11368318, 0.8733778] [0, 1, 0]\n",
      "संतोषजनक [0.00064382574, 0.9882361, 0.011119989] [0, 0, 1]\n",
      "जनसभाएं [0.38545415, 0.52713305, 0.08741277] [1, 0, 0]\n",
      "सीटू [0.88658017, 0.11051995, 0.002899904] [0, 1, 0]\n",
      "पंढे [0.0018835767, 0.99331576, 0.0048006247] [0, 0, 1]\n",
      "यूनियनों [0.002741952, 0.9804341, 0.016823914] [1, 0, 0]\n",
      "यूनियनों [0.002741952, 0.9804341, 0.016823914] [1, 0, 0]\n",
      "संधि [0.43854418, 0.521741, 0.039714873] [1, 0, 0]\n",
      "डी [0.8279949, 0.15071066, 0.021294476] [0, 1, 0]\n",
      "शकील [0.97391474, 0.011593468, 0.014491758] [0, 1, 0]\n",
      "फिराक़ [0.27524677, 0.4114803, 0.31327298] [1, 0, 0]\n",
      "डी [0.8279949, 0.15071066, 0.021294476] [0, 1, 0]\n",
      "नदियों [0.106943145, 0.8838721, 0.009184695] [1, 0, 0]\n",
      "नदियों [0.106943145, 0.8838721, 0.009184695] [1, 0, 0]\n",
      "नदियों [0.106943235, 0.883872, 0.009184694] [1, 0, 0]\n",
      "चौकन्ना [0.03773158, 0.93754655, 0.024721857] [0, 0, 1]\n",
      "चेतना [0.03778401, 0.95025414, 0.011961843] [0, 0, 1]\n",
      "महाशक्ति [0.27019367, 0.61049354, 0.119312756] [1, 0, 0]\n",
      "अग्रसर [0.0025890567, 0.5036898, 0.49372113] [0, 0, 1]\n",
      "लत [0.05594223, 0.9098277, 0.03423009] [1, 0, 0]\n",
      "मज़ार [0.010893244, 0.97049695, 0.018609779] [1, 0, 0]\n",
      "मज़ार [0.010893244, 0.97049695, 0.018609779] [1, 0, 0]\n",
      "जागीर [0.7377364, 0.2304526, 0.031811] [0, 1, 0]\n",
      "मज़ार [0.010893244, 0.97049695, 0.018609779] [1, 0, 0]\n",
      "मज़ार [0.010893244, 0.97049695, 0.018609779] [1, 0, 0]\n",
      "यूनीवर्सिटी [0.23587194, 0.74440277, 0.019725207] [1, 0, 0]\n",
      "फांस [0.05093503, 0.7934541, 0.15561081] [1, 0, 0]\n",
      "सवेर [0.06938786, 0.9166079, 0.014004146] [1, 0, 0]\n",
      "निबटना [0.17129801, 0.7425425, 0.086159505] [0, 0, 1]\n",
      "बताएं [0.1475594, 0.5361859, 0.31625473] [0, 0, 1]\n",
      "फांस [0.05093503, 0.7934541, 0.15561081] [1, 0, 0]\n",
      "लबरेज [0.017469466, 0.82899296, 0.15353763] [0, 0, 1]\n",
      "लाजमी [0.069982655, 0.8175721, 0.11244527] [0, 0, 1]\n",
      "एल्बो [0.1623838, 0.808165, 0.02945121] [1, 0, 0]\n",
      "नम [0.0028659916, 0.9932943, 0.0038396567] [0, 0, 1]\n",
      "जानतीं [0.13200033, 0.8529821, 0.015017647] [1, 0, 0]\n",
      "फैन [0.0021095912, 0.9923528, 0.0055376315] [0, 0, 1]\n",
      "अर्चना [0.45527962, 0.5158315, 0.028888855] [1, 0, 0]\n",
      "ऊखीमठ [0.78278995, 0.15562055, 0.061589442] [0, 1, 0]\n",
      "मोटर [0.3694258, 0.50766796, 0.1229062] [1, 0, 0]\n",
      "नौटियाल [0.07780302, 0.8631565, 0.059040416] [0, 0, 1]\n",
      "स्वीकृत [0.6157875, 0.0013089259, 0.38290355] [0, 0, 1]\n",
      "ढौंडियाल [0.0014988269, 0.99696785, 0.0015333584] [0, 0, 1]\n",
      "मैठाणी [0.70758617, 0.14681108, 0.14560269] [0, 0, 1]\n",
      "तिवाड़ी [0.7786135, 0.15606232, 0.06532426] [0, 0, 1]\n",
      "थपलियाल [0.007550116, 0.9842265, 0.008223292] [0, 0, 1]\n",
      "पीटा [0.8395154, 0.14688973, 0.013594858] [0, 1, 0]\n",
      "पीटा [0.8395154, 0.14688973, 0.013594858] [0, 1, 0]\n",
      "सूज [0.0117747625, 0.9569172, 0.031308047] [0, 0, 1]\n",
      "सहरावत [0.70387983, 0.24922748, 0.046892684] [0, 1, 0]\n",
      "नागर [0.003497043, 0.989739, 0.0067640413] [0, 0, 1]\n",
      "प्रमाणित [0.1649808, 0.77764785, 0.057371248] [0, 0, 1]\n",
      "कोठी [0.07597684, 0.6608732, 0.26314995] [1, 0, 0]\n",
      "हर्षाछीना [0.99785846, 0.0011206461, 0.0010208874] [0, 1, 0]\n",
      "खिलौने [0.019226933, 0.062279753, 0.91849333] [0, 1, 0]\n",
      "असलहे [0.04044345, 0.3129302, 0.64662635] [0, 1, 0]\n",
      "हर्षाछीना [0.99785846, 0.0011206461, 0.0010208874] [0, 1, 0]\n",
      "रिंग [0.025834354, 0.9642446, 0.00992112] [1, 0, 0]\n",
      "बीड्स [0.89476043, 0.09214807, 0.013091508] [0, 1, 0]\n",
      "मटर [0.20003398, 0.6885525, 0.11141357] [1, 0, 0]\n",
      "उकेरी [0.10899331, 0.64478827, 0.24621844] [1, 0, 0]\n",
      "कुषाणकालीन [0.041203607, 0.9540452, 0.0047512683] [0, 0, 1]\n",
      "प्रमाणित [0.1649808, 0.77764785, 0.057371248] [0, 0, 1]\n",
      "प्रथा [0.03197518, 0.89367175, 0.07435307] [1, 0, 0]\n",
      "कार्नीलियन [0.5723765, 0.3310264, 0.096597075] [0, 1, 0]\n",
      "कैटआई [0.99851125, 0.0005797373, 0.00090907887] [0, 1, 0]\n",
      "मनके [0.018974945, 0.063822836, 0.91720223] [0, 1, 0]\n",
      "श्रीदर्द [0.29691738, 0.33646342, 0.3666192] [0, 1, 0]\n",
      "खुदाइयों [0.16883421, 0.8033192, 0.027846554] [1, 0, 0]\n",
      "सुराही [0.3596419, 0.619898, 0.02046013] [1, 0, 0]\n",
      "खिलौने [0.019226933, 0.062279753, 0.91849333] [0, 1, 0]\n",
      "जालीदार [0.15979783, 0.8286714, 0.011530835] [0, 0, 1]\n",
      "औषधि [2.3104587e-05, 0.9999585, 1.8378365e-05] [1, 0, 0]\n",
      "डाइयां [0.0028571882, 0.9963793, 0.0007635065] [1, 0, 0]\n",
      "मृदाकला [0.013662742, 0.95824194, 0.02809527] [1, 0, 0]\n",
      "रदों [0.9950421, 0.0030917835, 0.0018660561] [0, 1, 0]\n",
      "दर्द [0.03920363, 0.41726857, 0.5435278] [0, 1, 0]\n",
      "नवलकर [0.033882316, 0.72974616, 0.23637153] [0, 0, 1]\n",
      "हक्सर [0.0019476197, 0.99590874, 0.0021435956] [0, 0, 1]\n",
      "तथ्यात्मक [0.9884996, 0.009614425, 0.0018859952] [0, 0, 1]\n",
      "हक्सर [0.0019476197, 0.99590874, 0.0021435956] [0, 0, 1]\n",
      "मक्कड़ [0.0008941852, 0.99889, 0.00021584108] [0, 0, 1]\n",
      "काबिज [0.015365097, 0.71188223, 0.27275267] [0, 0, 1]\n",
      "तेजासिंह [0.69722146, 0.1940763, 0.1087022] [0, 1, 0]\n",
      "लंगाह [0.47076935, 0.4849726, 0.044257943] [0, 0, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मक्कड़ [0.0008941852, 0.99889, 0.00021584108] [0, 0, 1]\n",
      "गोरा [0.0013267908, 0.9965139, 0.0021592886] [0, 0, 1]\n",
      "वार्कि [0.0032609573, 0.99160427, 0.0051346845] [0, 0, 1]\n",
      "भौर [0.01225887, 0.9432661, 0.044475053] [0, 0, 1]\n",
      "प्रधानगी [0.12776119, 0.8150693, 0.057169463] [1, 0, 0]\n",
      "डब्बोवाली [0.33909902, 0.6337581, 0.027142767] [0, 0, 1]\n",
      "समरा [0.003210329, 0.99041533, 0.0063742683] [0, 0, 1]\n",
      "करमुवाल [0.0032414733, 0.9756301, 0.021128427] [0, 0, 1]\n",
      "पट्टी [0.9943403, 0.0053664627, 0.00029321402] [0, 0, 1]\n",
      "नलवी [0.021184431, 0.96960497, 0.00921053] [0, 0, 1]\n",
      "मक्कड़ [0.0008941852, 0.99889, 0.00021584108] [0, 0, 1]\n",
      "पंजोली [0.724746, 0.21172762, 0.06352636] [0, 0, 1]\n",
      "नलवी [0.021184415, 0.96960515, 0.009210522] [0, 0, 1]\n",
      "विर्क [0.0045760055, 0.9883437, 0.007080315] [0, 0, 1]\n",
      "आखिरी [0.85558856, 0.121706426, 0.022704998] [0, 0, 1]\n",
      "पिथौरागढ़ [0.62714463, 0.325669, 0.04718636] [0, 1, 0]\n",
      "मैपिंग [0.033985704, 0.94202614, 0.023988148] [1, 0, 0]\n",
      "मैपिंग [0.033985704, 0.94202614, 0.023988148] [1, 0, 0]\n",
      "मुराद [0.21955317, 0.75271285, 0.02773408] [1, 0, 0]\n",
      "भुट्टो [0.0096379155, 0.9783611, 0.012001005] [0, 0, 1]\n",
      "बेनजीर [0.13522187, 0.7172777, 0.14750044] [1, 0, 0]\n",
      "मुराद [0.21955317, 0.75271285, 0.02773408] [1, 0, 0]\n",
      "मुराद [0.21955317, 0.75271285, 0.02773408] [1, 0, 0]\n",
      "मुराद [0.21955317, 0.75271285, 0.02773408] [1, 0, 0]\n",
      "बेनजीर [0.13522187, 0.7172777, 0.14750044] [1, 0, 0]\n",
      "1987 [0.005405834, 0.7120454, 0.2825488] [0, 0, 1]\n",
      "लालसा [0.022209305, 0.95278394, 0.025006674] [1, 0, 0]\n",
      "प्रसिद्ध [0.8419575, 0.000647285, 0.15739523] [0, 0, 1]\n",
      "रेलिंग [0.03193967, 0.94473565, 0.023324724] [1, 0, 0]\n",
      "1911 [0.010554029, 0.9630911, 0.026354797] [0, 0, 1]\n",
      "निष्कंटक [0.0008179419, 0.994541, 0.004641108] [0, 0, 1]\n",
      "मुंगेकर [0.021675168, 0.93021965, 0.048105236] [0, 0, 1]\n",
      "उच्च [0.005423148, 0.976096, 0.01848083] [0, 0, 1]\n",
      "तकनीक़ी [0.99999964, 4.587596e-13, 3.3511347e-07] [0, 0, 1]\n",
      "अपर्याप्त [0.049701657, 0.49234658, 0.45795175] [0, 0, 1]\n",
      "मुंगेकर [0.021675168, 0.93021965, 0.048105236] [0, 0, 1]\n",
      "उच्च [0.005423148, 0.976096, 0.01848083] [0, 0, 1]\n",
      "तकनीक़ी [0.99999964, 4.587596e-13, 3.3511347e-07] [0, 0, 1]\n",
      "खास [0.15730469, 0.49277115, 0.3499242] [0, 0, 1]\n",
      "3010 [0.04111152, 0.5598793, 0.39900917] [0, 0, 1]\n",
      "रिलीफ [0.9989537, 0.0006996316, 0.00034667502] [0, 1, 0]\n",
      "नर्स [0.0011345813, 0.9971636, 0.0017017266] [1, 0, 0]\n",
      "यूनीफॉर्म [0.11688757, 0.8365681, 0.046544302] [1, 0, 0]\n",
      "दुबके [0.05343805, 0.002810756, 0.9437512] [0, 1, 0]\n",
      "यमुनोत्री [0.17615023, 0.80232555, 0.02152424] [1, 0, 0]\n",
      "यमुनोत्री [0.17615023, 0.80232555, 0.02152424] [1, 0, 0]\n",
      "अवरुद्ध [0.002740093, 0.9431818, 0.054078165] [0, 0, 1]\n",
      "सुक्की [0.91030294, 0.08632228, 0.0033747924] [0, 1, 0]\n",
      "अवरुद्ध [0.002740093, 0.9431818, 0.054078165] [0, 0, 1]\n",
      "धराली [0.99792105, 0.0012855254, 0.00079350127] [0, 1, 0]\n",
      "गंगी [0.9997234, 0.00022053887, 5.6030636e-05] [0, 1, 0]\n",
      "पटागणियां [0.77233636, 0.18919586, 0.03846785] [0, 1, 0]\n",
      "पहाड़ियां [0.48049295, 0.49456337, 0.024943732] [1, 0, 0]\n",
      "अवरुद्ध [0.002740093, 0.9431818, 0.054078165] [0, 0, 1]\n",
      "बदरीनाथ [0.55372006, 0.40163597, 0.04464399] [0, 1, 0]\n",
      "पर्त [0.0029504786, 0.9956043, 0.0014451755] [1, 0, 0]\n",
      "औली [0.977444, 0.0141696315, 0.008386402] [0, 1, 0]\n",
      "पहाड़ियां [0.48049295, 0.49456337, 0.024943732] [1, 0, 0]\n",
      "रजामंद [0.002579133, 0.57630485, 0.421116] [0, 0, 1]\n",
      "शीतकाल [0.80077827, 0.18091771, 0.018304003] [0, 1, 0]\n",
      "सात [0.026894443, 0.6687287, 0.3043768] [0, 0, 1]\n",
      "कतारें [0.36489782, 0.5957411, 0.039361127] [1, 0, 0]\n",
      "अर्चना [0.45527962, 0.5158315, 0.028888855] [1, 0, 0]\n",
      "शीतकाल [0.80077827, 0.18091771, 0.018304003] [0, 1, 0]\n",
      "बांटा [0.030127471, 0.25922015, 0.7106524] [0, 1, 0]\n",
      "नौटियाल [0.07780302, 0.8631565, 0.059040416] [0, 0, 1]\n",
      "नबियाल [0.023691388, 0.96263266, 0.013676008] [0, 0, 1]\n",
      "डिमरी [0.58179665, 0.38131475, 0.03688863] [0, 0, 1]\n",
      "टम्टा [0.017027546, 0.936905, 0.046067376] [0, 0, 1]\n",
      "धुन [0.0051412107, 0.98695624, 0.007902542] [1, 0, 0]\n",
      "मंत्रमुग्ध [0.20167075, 0.777503, 0.02082625] [0, 0, 1]\n",
      "542\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "pred_data = prepare_sets(TEST_SRCS)\n",
    "print(len(pred_data))\n",
    "\n",
    "X_pred, y_pred = [], []\n",
    "# prepare_Xy_binary(pred_data, X_pred, y_pred)\n",
    "prepare_Xy_ternary(pred_data, X_pred, y_pred)\n",
    "# prepare_Xy_binary_multi_label(pred_data, X_pred, y_pred)\n",
    "\n",
    "X_pred_seq = tokenizer.texts_to_sequences(X_pred)\n",
    "X_pred_padded = pad_sequences(X_pred_seq, padding = \"post\", maxlen = max_length)\n",
    "\n",
    "predictions = model.predict(X_pred_padded)\n",
    "# print(predictions)\n",
    "\n",
    "model.evaluate(np.array(X_pred_padded), np.array(y_pred))\n",
    "\n",
    "print(predictions.shape)\n",
    "\n",
    "def orig_word(X):\n",
    "    ans = \"\"\n",
    "    for i in X:\n",
    "        if i == 0:\n",
    "            continue\n",
    "        ans += reverse_word_map[i]\n",
    "    return ans\n",
    "\n",
    "# for binary\n",
    "# cnt1 = 0\n",
    "# cnt2 = 0\n",
    "# cnt = 0\n",
    "# for X, y, pred in zip(X_pred_padded, y_pred, predictions):\n",
    "#     if y == 1 and pred < 0.5:\n",
    "#         cnt1 += 1\n",
    "#         for i in X:\n",
    "#             if i == 0:\n",
    "#                 continue\n",
    "#             print(reverse_word_map[i], end='')\n",
    "#         print(\" \", pred)\n",
    "#     elif y == 0 and pred > 0.5:\n",
    "#         cnt2 += 1\n",
    "#     cnt += 1\n",
    "\n",
    "# print(cnt1)\n",
    "# print(cnt2)\n",
    "# print(cnt)\n",
    "    \n",
    "\n",
    "# for ternary\n",
    "cnt = 0\n",
    "for X, y, pred in zip(X_pred_padded, y_pred, predictions):\n",
    "    pred = list(pred)\n",
    "    if y[pred.index(max(pred))] != 1:\n",
    "        print(orig_word(X), pred, y)\n",
    "        cnt += 1\n",
    "\n",
    "print(cnt)\n",
    "\n",
    "\n",
    "# for multi-label binary classification\n",
    "# cnt = 0\n",
    "# pred_cut_off = 0.5\n",
    "# for X, y, pred in zip(X_pred_padded, y_pred, predictions):\n",
    "#     correct = 0\n",
    "#     if y[0] > 0:\n",
    "#         correct += (pred[0] > pred_cut_off)\n",
    "#     else:\n",
    "#         correct += (pred[0] <= pred_cut_off)\n",
    "#     if y[1] > 0:\n",
    "#         correct += (pred[1] > pred_cut_off)\n",
    "#     else:\n",
    "#         correct += (pred[1] <= pred_cut_off)\n",
    "    \n",
    "#     if correct != 2:\n",
    "#         cnt += 1\n",
    "#         print(orig_word(X), pred, y)\n",
    "\n",
    "# print(cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
